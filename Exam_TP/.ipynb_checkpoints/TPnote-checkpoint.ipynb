{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e1a15c-d51b-4b51-ad1d-112e66e72272",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "TP noté\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5047989-47b2-4b2a-aa79-0ddd12a2a235",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Ce TP est noté. Il doit être fait exclusivement dans ce notebook Jupyter, que vous devrez remettre sur e-campus avant la fin de la séance.\n",
    "\n",
    "Il s'agit d'un travail individuel, à réaliser exclusivement sur les ordinateurs de l'université.\n",
    "\n",
    "Les outils d'IA génératifs (ChatGPT et autres) sont strictement interdits. Vous avez uniquement le droit d'accéder à ecampus et aux sites suivants: \n",
    "\n",
    "Langage utilisé:\n",
    "- Python 3: https://docs.python.org/3/\n",
    "\n",
    "Librairie de math:\n",
    "- Numpy: https://docs.scipy.org/doc/numpy/reference/\n",
    "\n",
    "Librairie d'affichage de données:\n",
    "- Matplotilb: https://matplotlib.org/contents.html\n",
    "\n",
    "Librairie de Deep Learning\n",
    "- PyTorch: https://pytorch.org/docs/stable/index.html\n",
    "- PyTorch Lightning: https://pytorch-lightning.readthedocs.io/en/stable/\n",
    "- Torchvision: https://pytorch.org/vision/stable/index.html\n",
    "- Torchmetrics: https://torchmetrics.readthedocs.io/en/stable/\n",
    "\n",
    "Données d'apprentissage \n",
    "- Wine Quality: https://archive.ics.uci.edu/dataset/186/wine+quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "23d0a056-e0ca-4027-9763-23ec57499de9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version torch: 2.0.0+cu117\n",
      "Versino lightning: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import os \n",
    "\n",
    "from typing import Dict, Iterator, List, Optional, Tuple, TypeVar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Version torch:',torch.__version__)\n",
    "print('Versino lightning:',pl.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4bffacc-8425-4fbf-8ede-fea6636a50d5",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "Nom: MESSILI \n",
    "Prénom: ISLEM\n",
    "Numéro d'étudiant: 22303045"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe2a7fa-67b6-4503-9823-2604f597f96e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "L'objectif de ce TP est de concevoir, d'entrainer et d'évaluer un réseau de neurones effectuant une tâche de régression sur le jeu de données [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality). \n",
    "\n",
    "Deux ensembles de données sont inclus, relatifs à des échantillons de \"Vinho verde\" rouge et blanc, provenant du nord du Portugal. Vous regrouperez ces deux ensembles en un unique ensemble. L'objectif est de modéliser la qualité du vin sur la base de tests physicochimiques. \n",
    "\n",
    "La valeur à régresser est le score, qui est un entier compris entre 0 et 10 mais que vous pourrez considérer comme une variable continue. Les attributs à utiliser pour régresser cette grandeur sont au nombre de 12, dont 11 valeurs continues ('fixed\\_acidity', 'volatile\\_acidity', 'citric\\_acid', 'residual\\_sugar', 'chlorides',\t'free\\_sulfur\\_dioxide', 'total\\_sulfur\\_dioxide', 'density', 'pH', 'sulphates', 'alcohol') et une valeur catégorielle ('color').\n",
    "\n",
    "Les étapes de ce TP sont les suivantes :\n",
    "1. Préparer les données et les batches en créant la classe `WineDataModule` qui hérite de\n",
    "`pl.LightningDataModule`.\n",
    "2. Construire un modèle de réseau de neurones et les méthodes nécessaires pour l’entraîner en créant la classe `MyModel` qui hérite de `pl.LightningModule`.\n",
    "3. Entraîner le modèle de l'étape 2 à l’aide des données préparées dans l’étape 1.\n",
    "\n",
    "Les codes informatiques que vous réaliserez pour les aspects *deep learning* feront appel aux librairies `Lightning` et `PyTorch`, vues durant les TPs précédant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e49cc-9812-4de2-a629-dc6096beeb02",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# 1- Création d'un LigthningDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229a759-24fe-4298-9fd2-5c24b4441c40",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Nous allons dans ce TP travailler sur la base [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality). Commencez par télécharger la base de données en cliquant sur le lien Download de la page de la base.\n",
    "\n",
    "Afin de gérer ce dataset, nous allons implémenter une classe `WineDataModule` héritant de [pl.LightningDataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html).\n",
    "\n",
    "Nous allons créer cette classe progressivement dans la suite du TP. Vous reviendriez modifier le bloc suivant au cours des différentes étapes décrites par la suite. \n",
    "\n",
    "Commencez par créer la classe `WineDataModule` héritant de `pl.LightningDataModule`. Vous déclarez un constructeur prenant et enregistrant les paramètres suivants: \n",
    "- un nom de dossier où est sauvegardé la base de donnée,\n",
    "- la taille des batches,\n",
    "- la proportion du dataset à utiliser pour la validation. \n",
    "- la proportion du dataset à utiliser pour le test. \n",
    "\n",
    "Pour cette question, construisez uniquement le constructeur. Les autres méthodes seront détaillées par la suite.\n",
    "\n",
    "On utilisera pas défaut des batches de 32 éléments et une répartition de 70\\% des données pour l'entrainement, 15\\% des données pour la validation et 15\\% des données pour le test. Veuillez prévoir ces valeurs dans les arguments par défaut du constructeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96fb9ac9-4e82-4a82-9633-5e7c1d8f0b93",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import extract_archive\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "class WineDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, data_dir: str, batch_size: int = 32, val_split: float = 0.15, test_split: float = 0.15):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "        \n",
    "        self.data_train = None\n",
    "        self.data_val = None\n",
    "        self.data_test = None\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \n",
    "        # Verifie que le fichier zip existe\n",
    "        zip_path = os.path.join(self.data_dir, \"wine+quality.zip\")\n",
    "        if not os.path.exists(zip_path):\n",
    "            print(\"File not found.\")\n",
    "            return\n",
    "\n",
    "        # Extraire le fichier zip\n",
    "        extract_archive(zip_path, self.data_dir)\n",
    "\n",
    "        # Recuperer les deux path\n",
    "        dataset_paths = []\n",
    "        for file in os.listdir(self.data_dir):\n",
    "            if file.endswith(\".csv\"):\n",
    "                dataset_paths.append(os.path.join(self.data_dir, file))\n",
    "\n",
    "        # Return paths\n",
    "        return dataset_paths\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "        red_data = np.genfromtxt(os.path.join(self.data_dir, \"winequality-red.csv\"), delimiter=\";\", skip_header=1)\n",
    "        white_data = np.genfromtxt(os.path.join(self.data_dir, \"winequality-white.csv\"), delimiter=\";\", skip_header=1)\n",
    "\n",
    "        # Concat\n",
    "        all_data = np.concatenate((red_data, white_data), axis=0)\n",
    "\n",
    "        # To tansor\n",
    "        all_data_tensor = torch.tensor(all_data, dtype=torch.float32)\n",
    "        \n",
    "        # Separation\n",
    "        features = all_data_tensor[:, :-1]\n",
    "        labels = all_data_tensor[:, -1]\n",
    "\n",
    "        # Decoupage\n",
    "        train_size = int((1 - self.val_split - self.test_split) * len(all_data))\n",
    "        val_size = int(self.val_split * len(all_data))\n",
    "        test_size = int(self.test_split * len(all_data))\n",
    "\n",
    "        train_features, train_labels = features[:train_size], labels[:train_size]\n",
    "        val_features, val_labels = features[train_size:train_size + val_size], labels[train_size:train_size + val_size]\n",
    "        test_features, test_labels = features[train_size + val_size:], labels[train_size + val_size:]\n",
    "        \n",
    "        print(\"Taille de train:\", train_features.shape[0])\n",
    "        print(\"Taille de val:\", val_features.shape[0])\n",
    "        print(\"Taille de test:\", test_features.shape[0])\n",
    "        \n",
    "        # Stage Fit\n",
    "        if stage == 'fit': \n",
    "            self.data_train = TensorDataset(train_features, train_labels)\n",
    "            self.data_val = TensorDataset(val_features, val_labels)\n",
    "\n",
    "        # Stage Test\n",
    "        if stage == 'test':\n",
    "            self.data_test = TensorDataset(test_features, test_labels)\n",
    "                                           \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f9def640-f30c-46be-96eb-3ba6ec2b4093",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Création d'un objet datamodule. A relancer à chaque modification de WineDataModule.\n",
    "datamodule = WineDataModule(data_dir=\"/home/messili231/Documents/Pytorch/TP_Notee_MESSILI_Islem/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80645afa-56c3-4a54-8af7-de93959f275d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Ajoutez une méthode `prepare_data`. Cette méthode permet la préparation des données. Dans notre cas, elle fera la décompression de l'archive que vous avez téléchargée précédemment avec la fonction `torchvision.datasets.utils.extract_archive`.\n",
    "\n",
    "Vérifiez que l'appel de la méthode permet bien décompresser le fichier de la base de données dans le dossier prévu à cet effet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c6447645-1e7e-4b86-aa0f-5cc25aa9ae8f",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/messili231/Documents/Pytorch/TP_Notee_MESSILI_Islem/data/winequality-red.csv',\n",
       " '/home/messili231/Documents/Pytorch/TP_Notee_MESSILI_Islem/data/winequality-white.csv']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "66755b21-7ead-43d6-a2f0-18d0da603125",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mwinequality.names\u001b[0m*    \u001b[01;32mwinequality-white.csv\u001b[0m*\r\n",
      "\u001b[01;32mwinequality-red.csv\u001b[0m*  \u001b[01;32mwine+quality.zip\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db31af2-29ec-42ed-a380-b88d9ce714ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Ajoutez une méthode `setup`. Cette méthode permet de définir des [Datasets Pytorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). Pour cela, vous utiliserez la méthode `torch.utils.data.TensorDataset` sur un `Tensor` contenant l'ensemble des données de la base, que vous aurez préalablement construit.\n",
    "\n",
    "La méthode `setup` à un argument nommé `stage`. Regardez dans la documentation son rôle et utilisez-le à bon escient. Cette variable pourra prendre les valeurs `None`, `test` ou `fit`. \n",
    "\n",
    "Vous stockerez les datasets dans les attributs: \n",
    "- data_train\n",
    "- data_val\n",
    "- data_test\n",
    "\n",
    "Ces trois attributs ne sont pas nécessairement définis en fonction de la valeur de `stage`. On supposera que la valeur `None` permet de tous les définir. \n",
    "\n",
    "Les grandes étapes à implémenter sont les suivantes:\n",
    "1) Les fichiers `winequality-red.csv` et `winequality-white`. Vous pouvez utiliser [np.genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) pour cette question. Attention, la première ligne doit être ignorée et les valeurs retournées doivent être des `float`.\n",
    "2) Concaténez les deux tableaux, on ignorera la couleur des vins. Convertissez le résultat en un tableau pytorch.\n",
    "3) Séparez les données et les labels à prédire. La valeur à prédire correspond à la dernière colonne des fichiers csv. \n",
    "4) Effectuez le découpage de la base en trois ensembles en fonction des répartitions passées au constructeur. Puis créez les trois tableaux demandés. \n",
    "\n",
    "Vous appellerez la méthode `setup` sans argument dans le bloc suivant pour tester votre code. Cette méthode ne retourne rien, mais vous pouvez vérifier la taille des datasets stocker dans les attributs dédiés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c8b0e388-8859-49a0-ab51-12390da40bf1",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n"
     ]
    }
   ],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30e82e-d4a5-4088-8d99-c5d49bc9adae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Écrivez la méthode `train_dataloader`. Cette méthode retourne un dataloader pytorch sur les données de `train`. Vous pourrez utiliser la classe [DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) avec les arguments appropriés. \n",
    "\n",
    "Vérifiez le bon fonctionnement de votre méthode en affichant toutes les valeurs du premier batch. Vous pourrez utiliser les méthodes `iter` et `next` pour récupérer uniquement le premier batch. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58aecdc8-d187-4aa2-8bb0-74b7155c3a28",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n",
      "Features:\n",
      "tensor([[7.4000e+00, 7.0000e-01, 0.0000e+00, 1.9000e+00, 7.6000e-02, 1.1000e+01,\n",
      "         3.4000e+01, 9.9780e-01, 3.5100e+00, 5.6000e-01, 9.4000e+00],\n",
      "        [7.8000e+00, 8.8000e-01, 0.0000e+00, 2.6000e+00, 9.8000e-02, 2.5000e+01,\n",
      "         6.7000e+01, 9.9680e-01, 3.2000e+00, 6.8000e-01, 9.8000e+00],\n",
      "        [7.8000e+00, 7.6000e-01, 4.0000e-02, 2.3000e+00, 9.2000e-02, 1.5000e+01,\n",
      "         5.4000e+01, 9.9700e-01, 3.2600e+00, 6.5000e-01, 9.8000e+00],\n",
      "        [1.1200e+01, 2.8000e-01, 5.6000e-01, 1.9000e+00, 7.5000e-02, 1.7000e+01,\n",
      "         6.0000e+01, 9.9800e-01, 3.1600e+00, 5.8000e-01, 9.8000e+00],\n",
      "        [7.4000e+00, 7.0000e-01, 0.0000e+00, 1.9000e+00, 7.6000e-02, 1.1000e+01,\n",
      "         3.4000e+01, 9.9780e-01, 3.5100e+00, 5.6000e-01, 9.4000e+00],\n",
      "        [7.4000e+00, 6.6000e-01, 0.0000e+00, 1.8000e+00, 7.5000e-02, 1.3000e+01,\n",
      "         4.0000e+01, 9.9780e-01, 3.5100e+00, 5.6000e-01, 9.4000e+00],\n",
      "        [7.9000e+00, 6.0000e-01, 6.0000e-02, 1.6000e+00, 6.9000e-02, 1.5000e+01,\n",
      "         5.9000e+01, 9.9640e-01, 3.3000e+00, 4.6000e-01, 9.4000e+00],\n",
      "        [7.3000e+00, 6.5000e-01, 0.0000e+00, 1.2000e+00, 6.5000e-02, 1.5000e+01,\n",
      "         2.1000e+01, 9.9460e-01, 3.3900e+00, 4.7000e-01, 1.0000e+01],\n",
      "        [7.8000e+00, 5.8000e-01, 2.0000e-02, 2.0000e+00, 7.3000e-02, 9.0000e+00,\n",
      "         1.8000e+01, 9.9680e-01, 3.3600e+00, 5.7000e-01, 9.5000e+00],\n",
      "        [7.5000e+00, 5.0000e-01, 3.6000e-01, 6.1000e+00, 7.1000e-02, 1.7000e+01,\n",
      "         1.0200e+02, 9.9780e-01, 3.3500e+00, 8.0000e-01, 1.0500e+01],\n",
      "        [6.7000e+00, 5.8000e-01, 8.0000e-02, 1.8000e+00, 9.7000e-02, 1.5000e+01,\n",
      "         6.5000e+01, 9.9590e-01, 3.2800e+00, 5.4000e-01, 9.2000e+00],\n",
      "        [7.5000e+00, 5.0000e-01, 3.6000e-01, 6.1000e+00, 7.1000e-02, 1.7000e+01,\n",
      "         1.0200e+02, 9.9780e-01, 3.3500e+00, 8.0000e-01, 1.0500e+01],\n",
      "        [5.6000e+00, 6.1500e-01, 0.0000e+00, 1.6000e+00, 8.9000e-02, 1.6000e+01,\n",
      "         5.9000e+01, 9.9430e-01, 3.5800e+00, 5.2000e-01, 9.9000e+00],\n",
      "        [7.8000e+00, 6.1000e-01, 2.9000e-01, 1.6000e+00, 1.1400e-01, 9.0000e+00,\n",
      "         2.9000e+01, 9.9740e-01, 3.2600e+00, 1.5600e+00, 9.1000e+00],\n",
      "        [8.9000e+00, 6.2000e-01, 1.8000e-01, 3.8000e+00, 1.7600e-01, 5.2000e+01,\n",
      "         1.4500e+02, 9.9860e-01, 3.1600e+00, 8.8000e-01, 9.2000e+00],\n",
      "        [8.9000e+00, 6.2000e-01, 1.9000e-01, 3.9000e+00, 1.7000e-01, 5.1000e+01,\n",
      "         1.4800e+02, 9.9860e-01, 3.1700e+00, 9.3000e-01, 9.2000e+00],\n",
      "        [8.5000e+00, 2.8000e-01, 5.6000e-01, 1.8000e+00, 9.2000e-02, 3.5000e+01,\n",
      "         1.0300e+02, 9.9690e-01, 3.3000e+00, 7.5000e-01, 1.0500e+01],\n",
      "        [8.1000e+00, 5.6000e-01, 2.8000e-01, 1.7000e+00, 3.6800e-01, 1.6000e+01,\n",
      "         5.6000e+01, 9.9680e-01, 3.1100e+00, 1.2800e+00, 9.3000e+00],\n",
      "        [7.4000e+00, 5.9000e-01, 8.0000e-02, 4.4000e+00, 8.6000e-02, 6.0000e+00,\n",
      "         2.9000e+01, 9.9740e-01, 3.3800e+00, 5.0000e-01, 9.0000e+00],\n",
      "        [7.9000e+00, 3.2000e-01, 5.1000e-01, 1.8000e+00, 3.4100e-01, 1.7000e+01,\n",
      "         5.6000e+01, 9.9690e-01, 3.0400e+00, 1.0800e+00, 9.2000e+00],\n",
      "        [8.9000e+00, 2.2000e-01, 4.8000e-01, 1.8000e+00, 7.7000e-02, 2.9000e+01,\n",
      "         6.0000e+01, 9.9680e-01, 3.3900e+00, 5.3000e-01, 9.4000e+00],\n",
      "        [7.6000e+00, 3.9000e-01, 3.1000e-01, 2.3000e+00, 8.2000e-02, 2.3000e+01,\n",
      "         7.1000e+01, 9.9820e-01, 3.5200e+00, 6.5000e-01, 9.7000e+00],\n",
      "        [7.9000e+00, 4.3000e-01, 2.1000e-01, 1.6000e+00, 1.0600e-01, 1.0000e+01,\n",
      "         3.7000e+01, 9.9660e-01, 3.1700e+00, 9.1000e-01, 9.5000e+00],\n",
      "        [8.5000e+00, 4.9000e-01, 1.1000e-01, 2.3000e+00, 8.4000e-02, 9.0000e+00,\n",
      "         6.7000e+01, 9.9680e-01, 3.1700e+00, 5.3000e-01, 9.4000e+00],\n",
      "        [6.9000e+00, 4.0000e-01, 1.4000e-01, 2.4000e+00, 8.5000e-02, 2.1000e+01,\n",
      "         4.0000e+01, 9.9680e-01, 3.4300e+00, 6.3000e-01, 9.7000e+00],\n",
      "        [6.3000e+00, 3.9000e-01, 1.6000e-01, 1.4000e+00, 8.0000e-02, 1.1000e+01,\n",
      "         2.3000e+01, 9.9550e-01, 3.3400e+00, 5.6000e-01, 9.3000e+00],\n",
      "        [7.6000e+00, 4.1000e-01, 2.4000e-01, 1.8000e+00, 8.0000e-02, 4.0000e+00,\n",
      "         1.1000e+01, 9.9620e-01, 3.2800e+00, 5.9000e-01, 9.5000e+00],\n",
      "        [7.9000e+00, 4.3000e-01, 2.1000e-01, 1.6000e+00, 1.0600e-01, 1.0000e+01,\n",
      "         3.7000e+01, 9.9660e-01, 3.1700e+00, 9.1000e-01, 9.5000e+00],\n",
      "        [7.1000e+00, 7.1000e-01, 0.0000e+00, 1.9000e+00, 8.0000e-02, 1.4000e+01,\n",
      "         3.5000e+01, 9.9720e-01, 3.4700e+00, 5.5000e-01, 9.4000e+00],\n",
      "        [7.8000e+00, 6.4500e-01, 0.0000e+00, 2.0000e+00, 8.2000e-02, 8.0000e+00,\n",
      "         1.6000e+01, 9.9640e-01, 3.3800e+00, 5.9000e-01, 9.8000e+00],\n",
      "        [6.7000e+00, 6.7500e-01, 7.0000e-02, 2.4000e+00, 8.9000e-02, 1.7000e+01,\n",
      "         8.2000e+01, 9.9580e-01, 3.3500e+00, 5.4000e-01, 1.0100e+01],\n",
      "        [6.9000e+00, 6.8500e-01, 0.0000e+00, 2.5000e+00, 1.0500e-01, 2.2000e+01,\n",
      "         3.7000e+01, 9.9660e-01, 3.4600e+00, 5.7000e-01, 1.0600e+01]])\n",
      "Labels:\n",
      "tensor([5., 5., 5., 6., 5., 5., 5., 7., 7., 5., 5., 5., 5., 5., 5., 5., 7., 5.,\n",
      "        4., 6., 6., 5., 5., 5., 6., 5., 5., 5., 5., 6., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# mode fit\n",
    "datamodule.setup(stage='fit')\n",
    "\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "batch_one = next(iter(train_dataloader))\n",
    "features, labels = batch_one\n",
    "\n",
    "print(\"Features:\")\n",
    "print(features)\n",
    "print(\"Labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c114144-e57c-4a46-856c-007c5fab1cf3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Faites de même pour les méthodes:\n",
    "- `val_dataloader` : renvoye un `DataLoader` sur les données de validation,\n",
    "- `test_dataloader` : renvoye un `DataLoader` sur les données de test,\n",
    "- `predict_dataloader`: renvoye aussi un `DataLoader` sur les données de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "91056a28-3b2f-45ab-9b16-01a85690ffa1",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n",
      "Features:\n",
      "tensor([[6.8000e+00, 2.6000e-01, 4.8000e-01, 6.2000e+00, 4.9000e-02, 5.5000e+01,\n",
      "         1.8200e+02, 9.9582e-01, 3.2100e+00, 4.5000e-01, 9.4000e+00],\n",
      "        [6.0000e+00, 2.8000e-01, 5.2000e-01, 5.0000e+00, 7.8000e-02, 3.0000e+01,\n",
      "         1.3900e+02, 9.9494e-01, 3.1000e+00, 3.6000e-01, 9.0000e+00],\n",
      "        [6.0000e+00, 2.8000e-01, 2.5000e-01, 1.8000e+00, 4.2000e-02, 8.0000e+00,\n",
      "         1.0800e+02, 9.9290e-01, 3.0800e+00, 5.5000e-01, 9.0000e+00],\n",
      "        [7.2000e+00, 2.0000e-01, 2.2000e-01, 1.6000e+00, 4.4000e-02, 1.7000e+01,\n",
      "         1.0100e+02, 9.9471e-01, 3.3700e+00, 5.3000e-01, 1.0000e+01],\n",
      "        [6.1000e+00, 2.7000e-01, 2.5000e-01, 1.8000e+00, 4.1000e-02, 9.0000e+00,\n",
      "         1.0900e+02, 9.9290e-01, 3.0800e+00, 5.4000e-01, 9.0000e+00],\n",
      "        [6.0000e+00, 2.8000e-01, 2.5000e-01, 1.8000e+00, 4.2000e-02, 8.0000e+00,\n",
      "         1.0800e+02, 9.9290e-01, 3.0800e+00, 5.5000e-01, 9.0000e+00],\n",
      "        [6.4000e+00, 2.9000e-01, 3.0000e-01, 2.9000e+00, 3.6000e-02, 2.5000e+01,\n",
      "         7.9000e+01, 9.9037e-01, 3.2900e+00, 6.0000e-01, 1.2400e+01],\n",
      "        [7.4000e+00, 3.5000e-01, 2.4000e-01, 6.0000e+00, 4.2000e-02, 2.8000e+01,\n",
      "         1.2300e+02, 9.9304e-01, 3.1400e+00, 4.4000e-01, 1.1300e+01],\n",
      "        [8.1000e+00, 1.2000e-01, 3.8000e-01, 9.0000e-01, 3.4000e-02, 3.6000e+01,\n",
      "         8.6000e+01, 9.9026e-01, 2.8000e+00, 5.5000e-01, 1.2000e+01],\n",
      "        [6.4000e+00, 1.2000e-01, 3.0000e-01, 1.1000e+00, 3.1000e-02, 3.7000e+01,\n",
      "         9.4000e+01, 9.8986e-01, 3.0100e+00, 5.6000e-01, 1.1700e+01],\n",
      "        [7.2000e+00, 2.0000e-01, 2.2000e-01, 1.6000e+00, 4.4000e-02, 1.7000e+01,\n",
      "         1.0100e+02, 9.9471e-01, 3.3700e+00, 5.3000e-01, 1.0000e+01],\n",
      "        [7.3000e+00, 4.0000e-01, 2.6000e-01, 5.4500e+00, 1.6000e-02, 2.6000e+01,\n",
      "         9.0000e+01, 9.8951e-01, 2.8400e+00, 5.4000e-01, 1.3200e+01],\n",
      "        [7.7000e+00, 1.1000e-01, 3.4000e-01, 1.4050e+01, 4.0000e-02, 4.1000e+01,\n",
      "         1.1400e+02, 9.9634e-01, 3.0700e+00, 5.9000e-01, 1.1000e+01],\n",
      "        [6.9000e+00, 2.3000e-01, 4.1000e-01, 8.0000e+00, 3.0000e-02, 3.0000e+01,\n",
      "         1.1400e+02, 9.9368e-01, 3.2200e+00, 5.4000e-01, 1.1000e+01],\n",
      "        [6.9000e+00, 3.8000e-01, 3.8000e-01, 1.3100e+01, 1.1200e-01, 1.4000e+01,\n",
      "         9.4000e+01, 9.9792e-01, 3.0200e+00, 4.8000e-01, 9.2000e+00],\n",
      "        [7.5000e+00, 3.8000e-01, 2.9000e-01, 4.9000e+00, 2.1000e-02, 3.8000e+01,\n",
      "         1.1300e+02, 9.9026e-01, 3.0800e+00, 4.8000e-01, 1.3000e+01],\n",
      "        [5.8000e+00, 1.9000e-01, 2.4000e-01, 1.3000e+00, 4.4000e-02, 3.8000e+01,\n",
      "         1.2800e+02, 9.9362e-01, 3.7700e+00, 6.0000e-01, 1.0600e+01],\n",
      "        [5.5000e+00, 3.4000e-01, 2.6000e-01, 2.2000e+00, 2.1000e-02, 3.1000e+01,\n",
      "         1.1900e+02, 9.8919e-01, 3.5500e+00, 4.9000e-01, 1.3000e+01],\n",
      "        [6.6000e+00, 2.3000e-01, 3.0000e-01, 1.4900e+01, 5.1000e-02, 3.3000e+01,\n",
      "         1.1800e+02, 9.9835e-01, 3.0400e+00, 5.4000e-01, 9.0000e+00],\n",
      "        [6.6000e+00, 2.3000e-01, 3.0000e-01, 1.4900e+01, 5.1000e-02, 3.3000e+01,\n",
      "         1.1800e+02, 9.9835e-01, 3.0400e+00, 5.4000e-01, 9.0000e+00],\n",
      "        [8.4000e+00, 3.1000e-01, 3.1000e-01, 9.5000e-01, 2.1000e-02, 5.2000e+01,\n",
      "         1.4800e+02, 9.9038e-01, 2.9300e+00, 3.2000e-01, 1.1500e+01],\n",
      "        [6.7000e+00, 2.0000e-01, 3.0000e-01, 1.4000e+00, 2.5000e-02, 1.7000e+01,\n",
      "         7.6000e+01, 9.9104e-01, 3.1100e+00, 4.4000e-01, 1.1000e+01],\n",
      "        [8.4000e+00, 3.1000e-01, 3.1000e-01, 9.5000e-01, 2.1000e-02, 5.2000e+01,\n",
      "         1.4800e+02, 9.9038e-01, 2.9300e+00, 3.2000e-01, 1.1500e+01],\n",
      "        [7.3000e+00, 2.6000e-01, 2.4000e-01, 1.7000e+00, 5.0000e-02, 1.0000e+01,\n",
      "         1.1200e+02, 9.9286e-01, 3.1100e+00, 4.3000e-01, 9.9000e+00],\n",
      "        [6.3000e+00, 2.2000e-01, 2.2000e-01, 5.6000e+00, 3.9000e-02, 3.1000e+01,\n",
      "         1.2800e+02, 9.9296e-01, 3.1200e+00, 4.6000e-01, 1.0400e+01],\n",
      "        [6.6000e+00, 2.3000e-01, 3.0000e-01, 1.4900e+01, 5.1000e-02, 3.3000e+01,\n",
      "         1.1800e+02, 9.9835e-01, 3.0400e+00, 5.4000e-01, 9.0000e+00],\n",
      "        [7.5000e+00, 1.9000e-01, 4.0000e-01, 7.1000e+00, 5.6000e-02, 5.0000e+01,\n",
      "         1.1000e+02, 9.9540e-01, 3.0600e+00, 5.2000e-01, 9.9000e+00],\n",
      "        [8.0000e+00, 1.4000e-01, 3.3000e-01, 1.2000e+00, 4.5000e-02, 7.1000e+01,\n",
      "         1.6200e+02, 9.9140e-01, 3.0700e+00, 4.7000e-01, 1.1000e+01],\n",
      "        [6.8000e+00, 3.2000e-01, 3.9000e-01, 9.6000e+00, 2.6000e-02, 3.4000e+01,\n",
      "         1.2400e+02, 9.9286e-01, 3.1800e+00, 3.5000e-01, 1.2100e+01],\n",
      "        [6.6000e+00, 2.3000e-01, 2.0000e-01, 1.1400e+01, 4.4000e-02, 4.5000e+01,\n",
      "         1.3100e+02, 9.9604e-01, 2.9600e+00, 5.1000e-01, 9.7000e+00],\n",
      "        [6.6000e+00, 2.3000e-01, 2.0000e-01, 1.1400e+01, 4.4000e-02, 4.5000e+01,\n",
      "         1.3100e+02, 9.9604e-01, 2.9600e+00, 5.1000e-01, 9.7000e+00],\n",
      "        [6.7000e+00, 3.6000e-01, 2.6000e-01, 7.9000e+00, 3.4000e-02, 3.9000e+01,\n",
      "         1.2300e+02, 9.9119e-01, 2.9900e+00, 3.0000e-01, 1.2200e+01]])\n",
      "Labels:\n",
      "tensor([6., 6., 5., 5., 5., 5., 7., 5., 6., 6., 5., 7., 7., 6., 5., 7., 5., 8.,\n",
      "        6., 6., 5., 6., 5., 5., 6., 6., 6., 6., 6., 6., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "# mode fit\n",
    "datamodule.setup(stage='fit')\n",
    "\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "\n",
    "batch_one_val = next(iter(val_dataloader))\n",
    "features, labels = batch_one_val\n",
    "\n",
    "print(\"Features:\")\n",
    "print(features)\n",
    "print(\"Labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b31796eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n",
      "Features:\n",
      "tensor([[6.7000e+00, 3.1000e-01, 3.0000e-01, 2.4000e+00, 3.8000e-02, 3.0000e+01,\n",
      "         8.3000e+01, 9.8867e-01, 3.0900e+00, 3.6000e-01, 1.2800e+01],\n",
      "        [8.6000e+00, 3.1000e-01, 3.0000e-01, 9.0000e-01, 4.5000e-02, 1.6000e+01,\n",
      "         1.0900e+02, 9.9249e-01, 2.9500e+00, 3.9000e-01, 1.0100e+01],\n",
      "        [8.6000e+00, 3.1000e-01, 3.0000e-01, 9.0000e-01, 4.5000e-02, 1.6000e+01,\n",
      "         1.0900e+02, 9.9249e-01, 2.9500e+00, 3.9000e-01, 1.0100e+01],\n",
      "        [8.6000e+00, 2.2000e-01, 3.3000e-01, 1.2000e+00, 3.1000e-02, 3.8000e+01,\n",
      "         9.5000e+01, 9.9239e-01, 2.8300e+00, 3.1000e-01, 1.0300e+01],\n",
      "        [6.9000e+00, 1.4000e-01, 2.9000e-01, 9.9000e+00, 5.6000e-02, 3.0000e+01,\n",
      "         9.1000e+01, 9.9512e-01, 3.1900e+00, 3.3000e-01, 9.9000e+00],\n",
      "        [6.5000e+00, 2.2000e-01, 3.1000e-01, 3.9000e+00, 4.6000e-02, 1.7000e+01,\n",
      "         1.0600e+02, 9.9098e-01, 3.1500e+00, 3.1000e-01, 1.1500e+01],\n",
      "        [6.6000e+00, 3.2000e-01, 4.7000e-01, 1.5600e+01, 6.3000e-02, 2.7000e+01,\n",
      "         1.7300e+02, 9.9872e-01, 3.1800e+00, 5.6000e-01, 9.0000e+00],\n",
      "        [6.6000e+00, 3.2000e-01, 4.7000e-01, 1.5600e+01, 6.3000e-02, 2.7000e+01,\n",
      "         1.7300e+02, 9.9872e-01, 3.1800e+00, 5.6000e-01, 9.0000e+00],\n",
      "        [6.1000e+00, 2.8000e-01, 2.6000e-01, 1.5000e+00, 3.0000e-02, 2.5000e+01,\n",
      "         1.0100e+02, 9.8894e-01, 3.0300e+00, 4.1000e-01, 1.2100e+01],\n",
      "        [6.2000e+00, 3.0000e-01, 2.8000e-01, 1.6000e+00, 3.6000e-02, 2.8000e+01,\n",
      "         1.0600e+02, 9.8825e-01, 3.1400e+00, 4.1000e-01, 1.3300e+01],\n",
      "        [6.9000e+00, 2.2000e-01, 2.8000e-01, 7.8000e+00, 5.0000e-02, 4.3000e+01,\n",
      "         1.1600e+02, 9.9326e-01, 3.2200e+00, 6.0000e-01, 1.1500e+01],\n",
      "        [8.7000e+00, 3.1000e-01, 2.1000e-01, 5.6000e+00, 3.9000e-02, 2.8000e+01,\n",
      "         6.7000e+01, 9.9328e-01, 2.9600e+00, 5.2000e-01, 1.1000e+01],\n",
      "        [7.3000e+00, 2.7000e-01, 3.0000e-01, 1.3000e+00, 4.0000e-02, 2.6000e+01,\n",
      "         8.4000e+01, 9.9222e-01, 3.2800e+00, 5.3000e-01, 1.0700e+01],\n",
      "        [7.0000e+00, 4.6000e-01, 2.0000e-01, 1.6700e+01, 4.6000e-02, 5.0000e+01,\n",
      "         1.8400e+02, 9.9898e-01, 3.0800e+00, 5.6000e-01, 9.4000e+00],\n",
      "        [5.7000e+00, 2.3000e-01, 2.5000e-01, 7.9500e+00, 4.2000e-02, 1.6000e+01,\n",
      "         1.0800e+02, 9.9486e-01, 3.4400e+00, 6.1000e-01, 1.0300e+01],\n",
      "        [6.5000e+00, 3.6000e-01, 3.6000e-01, 6.7000e+00, 1.8500e-01, 5.1500e+01,\n",
      "         1.5100e+02, 9.9528e-01, 3.1700e+00, 4.2000e-01, 9.3000e+00],\n",
      "        [8.2000e+00, 1.8000e-01, 3.8000e-01, 1.1000e+00, 4.0000e-02, 4.1000e+01,\n",
      "         9.2000e+01, 9.9062e-01, 2.8800e+00, 6.0000e-01, 1.2000e+01],\n",
      "        [6.2000e+00, 2.7000e-01, 3.2000e-01, 6.3000e+00, 4.8000e-02, 4.7000e+01,\n",
      "         1.5900e+02, 9.9282e-01, 3.2100e+00, 6.0000e-01, 1.1000e+01],\n",
      "        [6.9000e+00, 4.0000e-01, 3.7000e-01, 8.9000e+00, 5.3000e-02, 3.6000e+01,\n",
      "         1.4800e+02, 9.9600e-01, 3.1600e+00, 5.0000e-01, 9.3000e+00],\n",
      "        [4.9000e+00, 3.4500e-01, 3.4000e-01, 1.0000e+00, 6.8000e-02, 3.2000e+01,\n",
      "         1.4300e+02, 9.9138e-01, 3.2400e+00, 4.0000e-01, 1.0100e+01],\n",
      "        [7.2000e+00, 2.3000e-01, 3.9000e-01, 1.5000e+00, 5.3000e-02, 2.6000e+01,\n",
      "         1.0600e+02, 9.9166e-01, 3.1800e+00, 4.7000e-01, 1.1100e+01],\n",
      "        [6.4000e+00, 2.0000e-01, 1.5000e-01, 6.6000e+00, 4.6000e-02, 2.6000e+01,\n",
      "         1.1300e+02, 9.9408e-01, 2.9900e+00, 5.8000e-01, 9.9000e+00],\n",
      "        [6.1000e+00, 2.7000e-01, 3.2000e-01, 6.2000e+00, 4.8000e-02, 4.7000e+01,\n",
      "         1.6100e+02, 9.9281e-01, 3.2200e+00, 6.0000e-01, 1.1000e+01],\n",
      "        [6.2000e+00, 2.7000e-01, 3.2000e-01, 6.3000e+00, 4.8000e-02, 4.7000e+01,\n",
      "         1.5900e+02, 9.9282e-01, 3.2100e+00, 6.0000e-01, 1.1000e+01],\n",
      "        [6.0000e+00, 3.0000e-01, 3.3000e-01, 2.1000e+00, 4.2000e-02, 3.1000e+01,\n",
      "         1.2700e+02, 9.8964e-01, 3.3200e+00, 4.2000e-01, 1.2500e+01],\n",
      "        [6.1000e+00, 3.0000e-01, 3.2000e-01, 2.2000e+00, 4.2000e-02, 4.1000e+01,\n",
      "         1.4200e+02, 9.8952e-01, 3.3100e+00, 4.4000e-01, 1.2700e+01],\n",
      "        [5.7000e+00, 1.4000e-01, 3.0000e-01, 5.4000e+00, 4.5000e-02, 2.6000e+01,\n",
      "         1.0500e+02, 9.9469e-01, 3.3200e+00, 4.5000e-01, 9.3000e+00],\n",
      "        [6.9000e+00, 4.0000e-01, 3.7000e-01, 8.9000e+00, 5.3000e-02, 3.6000e+01,\n",
      "         1.4800e+02, 9.9600e-01, 3.1600e+00, 5.0000e-01, 9.3000e+00],\n",
      "        [4.9000e+00, 3.4500e-01, 3.4000e-01, 1.0000e+00, 6.8000e-02, 3.2000e+01,\n",
      "         1.4300e+02, 9.9138e-01, 3.2400e+00, 4.0000e-01, 1.0100e+01],\n",
      "        [6.3000e+00, 3.3000e-01, 2.0000e-01, 1.7900e+01, 6.6000e-02, 3.6000e+01,\n",
      "         1.6100e+02, 9.9910e-01, 3.1400e+00, 5.1000e-01, 8.8000e+00],\n",
      "        [7.0000e+00, 1.6000e-01, 3.0000e-01, 2.6000e+00, 4.3000e-02, 3.4000e+01,\n",
      "         9.0000e+01, 9.9047e-01, 2.8800e+00, 4.7000e-01, 1.1200e+01],\n",
      "        [8.4000e+00, 2.2000e-01, 3.0000e-01, 1.3000e+00, 3.8000e-02, 4.5000e+01,\n",
      "         1.2200e+02, 9.9178e-01, 3.1300e+00, 5.4000e-01, 1.0800e+01]])\n",
      "Labels:\n",
      "tensor([7., 5., 5., 5., 6., 5., 5., 5., 6., 6., 8., 4., 6., 5., 6., 5., 6., 6.,\n",
      "        5., 5., 6., 6., 6., 6., 6., 7., 5., 5., 5., 5., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "# mode test\n",
    "datamodule.setup(stage='test')\n",
    "\n",
    "test_dataloader = datamodule.test_dataloader()\n",
    "\n",
    "batch_one_test = next(iter(test_dataloader))\n",
    "features, labels = batch_one_test\n",
    "\n",
    "print(\"Features:\")\n",
    "print(features)\n",
    "print(\"Labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2cab8af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n",
      "Features:\n",
      "tensor([[6.7000e+00, 3.1000e-01, 3.0000e-01, 2.4000e+00, 3.8000e-02, 3.0000e+01,\n",
      "         8.3000e+01, 9.8867e-01, 3.0900e+00, 3.6000e-01, 1.2800e+01],\n",
      "        [8.6000e+00, 3.1000e-01, 3.0000e-01, 9.0000e-01, 4.5000e-02, 1.6000e+01,\n",
      "         1.0900e+02, 9.9249e-01, 2.9500e+00, 3.9000e-01, 1.0100e+01],\n",
      "        [8.6000e+00, 3.1000e-01, 3.0000e-01, 9.0000e-01, 4.5000e-02, 1.6000e+01,\n",
      "         1.0900e+02, 9.9249e-01, 2.9500e+00, 3.9000e-01, 1.0100e+01],\n",
      "        [8.6000e+00, 2.2000e-01, 3.3000e-01, 1.2000e+00, 3.1000e-02, 3.8000e+01,\n",
      "         9.5000e+01, 9.9239e-01, 2.8300e+00, 3.1000e-01, 1.0300e+01],\n",
      "        [6.9000e+00, 1.4000e-01, 2.9000e-01, 9.9000e+00, 5.6000e-02, 3.0000e+01,\n",
      "         9.1000e+01, 9.9512e-01, 3.1900e+00, 3.3000e-01, 9.9000e+00],\n",
      "        [6.5000e+00, 2.2000e-01, 3.1000e-01, 3.9000e+00, 4.6000e-02, 1.7000e+01,\n",
      "         1.0600e+02, 9.9098e-01, 3.1500e+00, 3.1000e-01, 1.1500e+01],\n",
      "        [6.6000e+00, 3.2000e-01, 4.7000e-01, 1.5600e+01, 6.3000e-02, 2.7000e+01,\n",
      "         1.7300e+02, 9.9872e-01, 3.1800e+00, 5.6000e-01, 9.0000e+00],\n",
      "        [6.6000e+00, 3.2000e-01, 4.7000e-01, 1.5600e+01, 6.3000e-02, 2.7000e+01,\n",
      "         1.7300e+02, 9.9872e-01, 3.1800e+00, 5.6000e-01, 9.0000e+00],\n",
      "        [6.1000e+00, 2.8000e-01, 2.6000e-01, 1.5000e+00, 3.0000e-02, 2.5000e+01,\n",
      "         1.0100e+02, 9.8894e-01, 3.0300e+00, 4.1000e-01, 1.2100e+01],\n",
      "        [6.2000e+00, 3.0000e-01, 2.8000e-01, 1.6000e+00, 3.6000e-02, 2.8000e+01,\n",
      "         1.0600e+02, 9.8825e-01, 3.1400e+00, 4.1000e-01, 1.3300e+01],\n",
      "        [6.9000e+00, 2.2000e-01, 2.8000e-01, 7.8000e+00, 5.0000e-02, 4.3000e+01,\n",
      "         1.1600e+02, 9.9326e-01, 3.2200e+00, 6.0000e-01, 1.1500e+01],\n",
      "        [8.7000e+00, 3.1000e-01, 2.1000e-01, 5.6000e+00, 3.9000e-02, 2.8000e+01,\n",
      "         6.7000e+01, 9.9328e-01, 2.9600e+00, 5.2000e-01, 1.1000e+01],\n",
      "        [7.3000e+00, 2.7000e-01, 3.0000e-01, 1.3000e+00, 4.0000e-02, 2.6000e+01,\n",
      "         8.4000e+01, 9.9222e-01, 3.2800e+00, 5.3000e-01, 1.0700e+01],\n",
      "        [7.0000e+00, 4.6000e-01, 2.0000e-01, 1.6700e+01, 4.6000e-02, 5.0000e+01,\n",
      "         1.8400e+02, 9.9898e-01, 3.0800e+00, 5.6000e-01, 9.4000e+00],\n",
      "        [5.7000e+00, 2.3000e-01, 2.5000e-01, 7.9500e+00, 4.2000e-02, 1.6000e+01,\n",
      "         1.0800e+02, 9.9486e-01, 3.4400e+00, 6.1000e-01, 1.0300e+01],\n",
      "        [6.5000e+00, 3.6000e-01, 3.6000e-01, 6.7000e+00, 1.8500e-01, 5.1500e+01,\n",
      "         1.5100e+02, 9.9528e-01, 3.1700e+00, 4.2000e-01, 9.3000e+00],\n",
      "        [8.2000e+00, 1.8000e-01, 3.8000e-01, 1.1000e+00, 4.0000e-02, 4.1000e+01,\n",
      "         9.2000e+01, 9.9062e-01, 2.8800e+00, 6.0000e-01, 1.2000e+01],\n",
      "        [6.2000e+00, 2.7000e-01, 3.2000e-01, 6.3000e+00, 4.8000e-02, 4.7000e+01,\n",
      "         1.5900e+02, 9.9282e-01, 3.2100e+00, 6.0000e-01, 1.1000e+01],\n",
      "        [6.9000e+00, 4.0000e-01, 3.7000e-01, 8.9000e+00, 5.3000e-02, 3.6000e+01,\n",
      "         1.4800e+02, 9.9600e-01, 3.1600e+00, 5.0000e-01, 9.3000e+00],\n",
      "        [4.9000e+00, 3.4500e-01, 3.4000e-01, 1.0000e+00, 6.8000e-02, 3.2000e+01,\n",
      "         1.4300e+02, 9.9138e-01, 3.2400e+00, 4.0000e-01, 1.0100e+01],\n",
      "        [7.2000e+00, 2.3000e-01, 3.9000e-01, 1.5000e+00, 5.3000e-02, 2.6000e+01,\n",
      "         1.0600e+02, 9.9166e-01, 3.1800e+00, 4.7000e-01, 1.1100e+01],\n",
      "        [6.4000e+00, 2.0000e-01, 1.5000e-01, 6.6000e+00, 4.6000e-02, 2.6000e+01,\n",
      "         1.1300e+02, 9.9408e-01, 2.9900e+00, 5.8000e-01, 9.9000e+00],\n",
      "        [6.1000e+00, 2.7000e-01, 3.2000e-01, 6.2000e+00, 4.8000e-02, 4.7000e+01,\n",
      "         1.6100e+02, 9.9281e-01, 3.2200e+00, 6.0000e-01, 1.1000e+01],\n",
      "        [6.2000e+00, 2.7000e-01, 3.2000e-01, 6.3000e+00, 4.8000e-02, 4.7000e+01,\n",
      "         1.5900e+02, 9.9282e-01, 3.2100e+00, 6.0000e-01, 1.1000e+01],\n",
      "        [6.0000e+00, 3.0000e-01, 3.3000e-01, 2.1000e+00, 4.2000e-02, 3.1000e+01,\n",
      "         1.2700e+02, 9.8964e-01, 3.3200e+00, 4.2000e-01, 1.2500e+01],\n",
      "        [6.1000e+00, 3.0000e-01, 3.2000e-01, 2.2000e+00, 4.2000e-02, 4.1000e+01,\n",
      "         1.4200e+02, 9.8952e-01, 3.3100e+00, 4.4000e-01, 1.2700e+01],\n",
      "        [5.7000e+00, 1.4000e-01, 3.0000e-01, 5.4000e+00, 4.5000e-02, 2.6000e+01,\n",
      "         1.0500e+02, 9.9469e-01, 3.3200e+00, 4.5000e-01, 9.3000e+00],\n",
      "        [6.9000e+00, 4.0000e-01, 3.7000e-01, 8.9000e+00, 5.3000e-02, 3.6000e+01,\n",
      "         1.4800e+02, 9.9600e-01, 3.1600e+00, 5.0000e-01, 9.3000e+00],\n",
      "        [4.9000e+00, 3.4500e-01, 3.4000e-01, 1.0000e+00, 6.8000e-02, 3.2000e+01,\n",
      "         1.4300e+02, 9.9138e-01, 3.2400e+00, 4.0000e-01, 1.0100e+01],\n",
      "        [6.3000e+00, 3.3000e-01, 2.0000e-01, 1.7900e+01, 6.6000e-02, 3.6000e+01,\n",
      "         1.6100e+02, 9.9910e-01, 3.1400e+00, 5.1000e-01, 8.8000e+00],\n",
      "        [7.0000e+00, 1.6000e-01, 3.0000e-01, 2.6000e+00, 4.3000e-02, 3.4000e+01,\n",
      "         9.0000e+01, 9.9047e-01, 2.8800e+00, 4.7000e-01, 1.1200e+01],\n",
      "        [8.4000e+00, 2.2000e-01, 3.0000e-01, 1.3000e+00, 3.8000e-02, 4.5000e+01,\n",
      "         1.2200e+02, 9.9178e-01, 3.1300e+00, 5.4000e-01, 1.0800e+01]])\n",
      "Labels:\n",
      "tensor([7., 5., 5., 5., 6., 5., 5., 5., 6., 6., 8., 4., 6., 5., 6., 5., 6., 6.,\n",
      "        5., 5., 6., 6., 6., 6., 6., 7., 5., 5., 5., 5., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "# mode test\n",
    "datamodule.setup(stage='test')\n",
    "\n",
    "predict_dataloader = datamodule.predict_dataloader()\n",
    "\n",
    "batch_one_predict = next(iter(predict_dataloader))\n",
    "features, labels = batch_one_predict\n",
    "\n",
    "print(\"Features:\")\n",
    "print(features)\n",
    "print(\"Labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666dbe72-cb81-431a-a37d-43883987601e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# 2- Mise en place du réseau de neurone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0be98-7c98-4187-ade1-82804888667c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Nous allons dans cette partie construire le modèle en utilisant le même principe que la partie précédente. \n",
    "\n",
    "Commencez par créer la classe `MyModel` héritant de [pl.LightningModule](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html). Vous définirez un constructeur prenant les arguments suivant: \n",
    "- lr: le *learning rate*  (0.01 par défaut),\n",
    "- weight_decay: le poids de la régularisation ($10^{-5}$ par défaut),\n",
    "- *args : d'autres arguments non nommés,\n",
    "- **kwargs: : d'autres arguments nommés. \n",
    "\n",
    "Dans ce constructeur, vous effectuerez les étapes suivantes: \n",
    "- sauvegarde des paramètres d'entrées en utilisant `save_hyperparameters`.\n",
    "- définition d'un réseau dont l'architecture est la suivante: \n",
    "    - couche linéaire à 8 sorties + ReLU\n",
    "    - couche linéaire à 8 sorties + ReLU\n",
    "    - couche linéaire à une sortie\n",
    "- Définissez d'un objet de type `nn.MSELoss` pour train, val et test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4e02a5e7-89cd-4eab-94ca-d07db1b4619f",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModel(pl.LightningModule):\n",
    "    # init\n",
    "    def __init__(self, lr=0.01, weight_decay=1e-5, *args, **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Architecture NN\n",
    "        self.fc1 = nn.Linear(11, 8)\n",
    "        self.fc2 = nn.Linear(8, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "\n",
    "        # loss\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, num_batch):\n",
    "        \n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y_pred, y)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, num_batch):\n",
    "        \n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y_pred, y)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def test_step(self, batch, num_batch):\n",
    "        \n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y_pred, y)\n",
    "        self.log('test_loss', loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr,\n",
    "                                     weight_decay=self.weight_decay)\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "005c55f2-3b60-4daa-9ddd-468596db3687",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Création d'un objet MyModel. A relancer à chaque modification de MyModel.\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31dacd6-c070-48eb-8f80-929486d430a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Définissez une méthode `forward` qui calcule la sortie du réseau en fonction de son entrée. Testez votre méthode avec un tableau aléatoire de taille $(32,11)$. Vous pouvez utiliser la fonction [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8b86f232-e928-4f1e-972d-46d4a6082732",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 1])\n",
      "tensor([[-0.2454],\n",
      "        [-0.2241],\n",
      "        [-0.2002],\n",
      "        [-0.2441],\n",
      "        [-0.2394],\n",
      "        [-0.2207],\n",
      "        [-0.2087],\n",
      "        [-0.2186],\n",
      "        [-0.2315],\n",
      "        [-0.2345],\n",
      "        [-0.2393],\n",
      "        [-0.2441],\n",
      "        [-0.2316],\n",
      "        [-0.2256],\n",
      "        [-0.2652],\n",
      "        [-0.2215],\n",
      "        [-0.2363],\n",
      "        [-0.2274],\n",
      "        [-0.2686],\n",
      "        [-0.2071],\n",
      "        [-0.2505],\n",
      "        [-0.2187],\n",
      "        [-0.2425],\n",
      "        [-0.2457],\n",
      "        [-0.2372],\n",
      "        [-0.2397],\n",
      "        [-0.2149],\n",
      "        [-0.2281],\n",
      "        [-0.2363],\n",
      "        [-0.2287],\n",
      "        [-0.2205],\n",
      "        [-0.2204]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tensor_random = torch.rand(32, 11)\n",
    "\n",
    "output_tensor = model.forward(tensor_random)\n",
    "\n",
    "print(\"Output shape:\", output_tensor.shape)\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b244cfa-78dd-46cc-be0e-8e5e8d5be083",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Définissez la méthode `training_step`. Cette méthode calcul la sortie du réseau pour un batch donné puis évalue la fonction de coût (qu'elle retournera). Vous effectuerez également les logs de la fonction de coût.  \n",
    "\n",
    "Récupérez le premier batch avec le `datamodule` de la première partie et testez votre fonction. Le deuxième paramètre sera mis à 0 pour ce test.\n",
    "\n",
    "Vérifiez que votre fonction retourne bien une valeur pour la loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0d8078c1-45fa-4152-9bab-9e1972e7f646",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n",
      "Loss: 23.43031120300293\n"
     ]
    }
   ],
   "source": [
    "# mode fit\n",
    "datamodule.setup(stage='fit')\n",
    "\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "batch_one = next(iter(train_dataloader))\n",
    "\n",
    "loss = model.training_step(batch_one, 0)\n",
    "\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0b1712-1691-4933-9ffe-998668eebaeb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Définissez la méthode `validation_step` effectuant le traitement d'un batch sur les données de validation. Cette méthode est très similaire à la précédente hormis le fait qu'elle ne retourne rien.\n",
    "\n",
    "Testez la méthode en la lançant. Il ne devrait rien s'afficher, mais vous ne devez pas avoir d'erreur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6554601d-bd7e-4e07-8425-fa18efc2c1c0",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n"
     ]
    }
   ],
   "source": [
    "# mode fit\n",
    "datamodule.setup(stage='fit')\n",
    "\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "\n",
    "batch_one_val = next(iter(val_dataloader))\n",
    "\n",
    "model.validation_step(batch_one_val, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fea409-6aa0-4226-9bef-b43a7a4eb398",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Définissez de la même manière que précédemment la méthode `test_step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ccc07210-b804-4b39-8826-ccf202065fab",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n"
     ]
    }
   ],
   "source": [
    "# mode test\n",
    "datamodule.setup(stage='test')\n",
    "\n",
    "test_dataloader = datamodule.test_dataloader()\n",
    "\n",
    "batch_one_test = next(iter(test_dataloader))\n",
    "\n",
    "model.test_step(batch_one_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ca0b2-87eb-4953-9755-9244bf88050b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Définissez la méthode `configure_optimizers` qui retourne le ou les optimiseurs choisis pour entrainer le réseau. Nous utiliserons ici un optimiser d'[Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html).\n",
    "\n",
    "Lancez votre méthode pour en vérifier le bon fonctionnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3c636be7-fc51-43ed-9c47-5138a7e02cc5",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 1e-05\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = model.configure_optimizers()\n",
    "\n",
    "print(\"Optimizer:\", optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a868434-011e-4f65-b598-084e6d03d14d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# 3- Entraînement du modèle et test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a5b2c-d045-4428-982a-33736452dc24",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Nous avons précédemment défini tous les éléments important pour apprendre notre réseau. \n",
    "En utilisant un objet de type [Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html), faites un apprentissage sur 5 époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6d6bda44-9fcb-46ad-a51c-de254423a064",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type    | Params\n",
      "---------------------------------\n",
      "0 | fc1  | Linear  | 96    \n",
      "1 | fc2  | Linear  | 72    \n",
      "2 | fc3  | Linear  | 9     \n",
      "3 | loss | MSELoss | 0     \n",
      "---------------------------------\n",
      "177       Trainable params\n",
      "0         Non-trainable params\n",
      "177       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63556c258fb458ba78d6099592317fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# Trainer 5 époques\n",
    "trainer = pl.Trainer(max_epochs=5)\n",
    "\n",
    "# Fit\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad734a4d-de29-4516-9158-6ab5e3021d4b",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:148: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /home/lechervy/Documents/save-cours-m2-deep-learning/TP/TP_note/2023-2024/lightning_logs/version_0/checkpoints/epoch=4-step=715.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/lechervy/Documents/save-cours-m2-deep-learning/TP/TP_note/2023-2024/lightning_logs/version_0/checkpoints/epoch=4-step=715.ckpt\n",
      "/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09183e65325a4c20a73741ca30811c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8456656336784363     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8456656336784363    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.8456656336784363}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainer 5 époques\n",
    "trainer = pl.Trainer(max_epochs=5)\n",
    "\n",
    "# Fit\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede56c2-2582-4cb2-af92-65bf2fe0a0da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "En utilisant la méthode `test` de `Trainer` précédent, obtenez les performances sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d04de4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:148: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /home/messili231/Documents/Pytorch/TP_Notee_MESSILI_Islem/lightning_logs/version_3/checkpoints/epoch=4-step=715.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/messili231/Documents/Pytorch/TP_Notee_MESSILI_Islem/lightning_logs/version_3/checkpoints/epoch=4-step=715.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de train: 4547\n",
      "Taille de val: 974\n",
      "Taille de test: 976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ea25c7d94d45f7a1ca69b89099b311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/tp_deep_learning/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6859560608863831     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6859560608863831    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6859560608863831}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1323deb6-5843-40f8-a999-d3173d78664b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# 4- Amélioration du réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf803a1-2a1b-493a-9df8-d5dd10227e61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Plutôt que d'utiliser un nombre d'époques fixes, mettre en place un mécanisme permettant de stopper l'entrainement quand la fonction de perte mesurée sur les données de validation ne décroit plus. Utiliser par exemple la méthode proposée [ici](https://lightning.ai/docs/pytorch/stable/common/early_stopping.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "42e34e12-cd96-4da4-9f17-2e7358c9cf0b",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a parent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [139], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      3\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, datamodule)\n",
      "File \u001b[0;32m/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/utilities/argparse.py:69\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:421\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate_grad_batches \u001b[38;5;241m=\u001b[39m accumulate_grad_batches\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# init callbacks\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Declare attributes to be set in _callback_connector on_trainer_init\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trainer_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_checkpointing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_root_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_model_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# init data flags\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_val_every_n_epoch: Optional[\u001b[38;5;28mint\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/callback_connector.py:79\u001b[0m, in \u001b[0;36m_CallbackConnector.on_trainer_init\u001b[0;34m(self, callbacks, enable_checkpointing, enable_progress_bar, default_root_dir, enable_model_summary, max_time)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_model_summary_callback(enable_model_summary)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mextend(_configure_external_callbacks())\n\u001b[0;32m---> 79\u001b[0m \u001b[43m_validate_callbacks_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# push all model checkpoint callbacks to the end\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# it is important that these are the last callbacks to run\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reorder_callbacks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks)\n",
      "File \u001b[0;32m/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/callback_connector.py:252\u001b[0m, in \u001b[0;36m_validate_callbacks_list\u001b[0;34m(callbacks)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_callbacks_list\u001b[39m(callbacks: List[Callback]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m     stateful_callbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks \u001b[38;5;28;01mif\u001b[39;00m is_overridden(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m, instance\u001b[38;5;241m=\u001b[39mcb)]\n\u001b[1;32m    253\u001b[0m     seen_callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m stateful_callbacks:\n",
      "File \u001b[0;32m/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/callback_connector.py:252\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_callbacks_list\u001b[39m(callbacks: List[Callback]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m     stateful_callbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_overridden\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    253\u001b[0m     seen_callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m stateful_callbacks:\n",
      "File \u001b[0;32m/usr/local/tp_deep_learning/lib/python3.8/site-packages/lightning/pytorch/utilities/model_helpers.py:34\u001b[0m, in \u001b[0;36mis_overridden\u001b[0;34m(method_name, instance, parent)\u001b[0m\n\u001b[1;32m     32\u001b[0m         parent \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mCallback\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a parent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_overridden \u001b[38;5;28;01mas\u001b[39;00m _is_overridden\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _is_overridden(method_name, instance, parent)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a parent"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "trainer_early_stop = pl.Trainer(callbacks=[early_stop])\n",
    "\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626dbe9-4a41-40a5-83d6-d405d0d6a7c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Définissez `MyResModel` consistant à en une classe similaire à `MyModel`, mais en changeant le réseau de neurones précédant de manière à lui ajouter une couche résiduelle au niveau de la couche cachées ayant le même nombre de canaux d'entrée que de sortie. Mesurer à nouveau la performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd71165b-caad-48fd-ac14-81b619ec21ca",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type     | Params\n",
      "----------------------------------------\n",
      "0 | net        | ResModel | 69.1 K\n",
      "1 | loss_train | MSELoss  | 0     \n",
      "2 | loss_val   | MSELoss  | 0     \n",
      "3 | loss_test  | MSELoss  | 0     \n",
      "----------------------------------------\n",
      "69.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "69.1 K    Total params\n",
      "0.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e199de20bb3544809aea273b7f4f71e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/lechervy/Documents/save-cours-m2-deep-learning/TP/TP_note/2023-2024/lightning_logs/version_2/checkpoints/epoch=6-step=1001.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/lechervy/Documents/save-cours-m2-deep-learning/TP/TP_note/2023-2024/lightning_logs/version_2/checkpoints/epoch=6-step=1001.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085aac06ac1e424891a5a74e81f55ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8240514397621155     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8240514397621155    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.8240514397621155}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960da59-9341-44e4-a88d-eee84bde8378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
