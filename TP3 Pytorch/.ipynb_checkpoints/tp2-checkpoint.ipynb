{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP2: Premier réseau de neurone avec PyTorch\n",
    "=============\n",
    "\n",
    "Introduction au sujet\n",
    "-----\n",
    "\n",
    "L'objectif de ce sujet est de mettre en place un premier réseau de neurone pour classer des fleurs de la base IRIS.\n",
    "\n",
    "Le code est à écrire en python3 à la suite des questions dans ce fichier. Vous appuierez soit sur le bouton *run cell*, soit sur les touches *Ctrl-Entrée*, à l’intérieur de la zone de saisie, pour lancer l'exécution de vos commandes. Si la commande est en cours d’exécution une étoile apparaît à côté de la zone de saisie de la commande : In [\\*]. Une fois le calcul achevé, l'étoile est remplacée par le numéro du run permettant de retrouver par la suite dans quel ordre ont été lancés chaque bloc.\n",
    "\n",
    "N'hésitez pas à regarder régulièrement la documentation de ces librairies, des exemples d'utilisation accompagnent généralement l'explication de chaque fonction.\n",
    "\n",
    "Langage utilisé:\n",
    "- Python 3: https://docs.python.org/3/\n",
    "\n",
    "Librairie de math:\n",
    "- Numpy: https://docs.scipy.org/doc/numpy/reference/\n",
    "- Scipy: https://docs.scipy.org/doc/scipy/reference/\n",
    "\n",
    "Librairie d'affichage de données:\n",
    "- Matplotilb: https://matplotlib.org/contents.html\n",
    "\n",
    "Librairie Pytorch:\n",
    "- PyTorch: https: https://pytorch.org/docs/stable/\n",
    "\n",
    "Commencez par importer les librairies nécessaires au TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.10 are installed in '/home/messili231/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pip-24.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch) (2.4)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.3.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading fsspec-2024.3.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: typing-extensions, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/messili231/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mSuccessfully installed fsspec-2024.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 torch-2.2.1 triton-2.2.0 typing-extensions-4.10.0\n",
      "Name: torch\n",
      "Version: 2.2.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/messili231/.local/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
      "Required-by: \n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: torch==2.2.1 in /home/messili231/.local/lib/python3.10/site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch==2.2.1->torchvision) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch==2.2.1->torchvision) (1.9)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch==2.2.1->torchvision) (2.4)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.2.1->torchvision) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2024.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/messili231/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/messili231/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.4.99)\n",
      "Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard) (3.3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/lib/python3/dist-packages (from tensorboard) (1.21.5)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-5.26.0-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (59.6.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.26.0-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tensorboard-data-server, protobuf, MarkupSafe, grpcio, absl-py, werkzeug, tensorboard\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/messili231/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 absl-py-2.1.0 grpcio-1.62.1 protobuf-5.26.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 werkzeug-3.0.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/lib/python3/dist-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.1.post1 threadpoolctl-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch\n",
    "!pip show torch\n",
    "!pip install torchvision\n",
    "!pip install tensorboard\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Import numpy et matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import de scikit-learn\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch: Premier réseau sur la base IRIS\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans ce TP étudier la base *IRIS* et tester un réseau entièrement connecté dessus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencez par charger la base *IRIS* avec sckit-learn. Vous mettrez les descripteurs des fleurs dans une variable `X` et les labels dans une variable `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X,y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length sepal_width petal_length petal_width species\n",
      "5.1\t\t3.5\t\t1.4\t\t0.2\t\t0\n",
      "4.9\t\t3.0\t\t1.4\t\t0.2\t\t0\n",
      "4.7\t\t3.2\t\t1.3\t\t0.2\t\t0\n",
      "4.6\t\t3.1\t\t1.5\t\t0.2\t\t0\n",
      "5.0\t\t3.6\t\t1.4\t\t0.2\t\t0\n",
      "5.4\t\t3.9\t\t1.7\t\t0.4\t\t0\n",
      "4.6\t\t3.4\t\t1.4\t\t0.3\t\t0\n",
      "5.0\t\t3.4\t\t1.5\t\t0.2\t\t0\n",
      "4.4\t\t2.9\t\t1.4\t\t0.2\t\t0\n",
      "4.9\t\t3.1\t\t1.5\t\t0.1\t\t0\n",
      "5.4\t\t3.7\t\t1.5\t\t0.2\t\t0\n",
      "4.8\t\t3.4\t\t1.6\t\t0.2\t\t0\n",
      "4.8\t\t3.0\t\t1.4\t\t0.1\t\t0\n",
      "4.3\t\t3.0\t\t1.1\t\t0.1\t\t0\n",
      "5.8\t\t4.0\t\t1.2\t\t0.2\t\t0\n",
      "5.7\t\t4.4\t\t1.5\t\t0.4\t\t0\n",
      "5.4\t\t3.9\t\t1.3\t\t0.4\t\t0\n",
      "5.1\t\t3.5\t\t1.4\t\t0.3\t\t0\n",
      "5.7\t\t3.8\t\t1.7\t\t0.3\t\t0\n",
      "5.1\t\t3.8\t\t1.5\t\t0.3\t\t0\n",
      "5.4\t\t3.4\t\t1.7\t\t0.2\t\t0\n",
      "5.1\t\t3.7\t\t1.5\t\t0.4\t\t0\n",
      "4.6\t\t3.6\t\t1.0\t\t0.2\t\t0\n",
      "5.1\t\t3.3\t\t1.7\t\t0.5\t\t0\n",
      "4.8\t\t3.4\t\t1.9\t\t0.2\t\t0\n",
      "5.0\t\t3.0\t\t1.6\t\t0.2\t\t0\n",
      "5.0\t\t3.4\t\t1.6\t\t0.4\t\t0\n",
      "5.2\t\t3.5\t\t1.5\t\t0.2\t\t0\n",
      "5.2\t\t3.4\t\t1.4\t\t0.2\t\t0\n",
      "4.7\t\t3.2\t\t1.6\t\t0.2\t\t0\n",
      "4.8\t\t3.1\t\t1.6\t\t0.2\t\t0\n",
      "5.4\t\t3.4\t\t1.5\t\t0.4\t\t0\n",
      "5.2\t\t4.1\t\t1.5\t\t0.1\t\t0\n",
      "5.5\t\t4.2\t\t1.4\t\t0.2\t\t0\n",
      "4.9\t\t3.1\t\t1.5\t\t0.2\t\t0\n",
      "5.0\t\t3.2\t\t1.2\t\t0.2\t\t0\n",
      "5.5\t\t3.5\t\t1.3\t\t0.2\t\t0\n",
      "4.9\t\t3.6\t\t1.4\t\t0.1\t\t0\n",
      "4.4\t\t3.0\t\t1.3\t\t0.2\t\t0\n",
      "5.1\t\t3.4\t\t1.5\t\t0.2\t\t0\n",
      "5.0\t\t3.5\t\t1.3\t\t0.3\t\t0\n",
      "4.5\t\t2.3\t\t1.3\t\t0.3\t\t0\n",
      "4.4\t\t3.2\t\t1.3\t\t0.2\t\t0\n",
      "5.0\t\t3.5\t\t1.6\t\t0.6\t\t0\n",
      "5.1\t\t3.8\t\t1.9\t\t0.4\t\t0\n",
      "4.8\t\t3.0\t\t1.4\t\t0.3\t\t0\n",
      "5.1\t\t3.8\t\t1.6\t\t0.2\t\t0\n",
      "4.6\t\t3.2\t\t1.4\t\t0.2\t\t0\n",
      "5.3\t\t3.7\t\t1.5\t\t0.2\t\t0\n",
      "5.0\t\t3.3\t\t1.4\t\t0.2\t\t0\n",
      "7.0\t\t3.2\t\t4.7\t\t1.4\t\t1\n",
      "6.4\t\t3.2\t\t4.5\t\t1.5\t\t1\n",
      "6.9\t\t3.1\t\t4.9\t\t1.5\t\t1\n",
      "5.5\t\t2.3\t\t4.0\t\t1.3\t\t1\n",
      "6.5\t\t2.8\t\t4.6\t\t1.5\t\t1\n",
      "5.7\t\t2.8\t\t4.5\t\t1.3\t\t1\n",
      "6.3\t\t3.3\t\t4.7\t\t1.6\t\t1\n",
      "4.9\t\t2.4\t\t3.3\t\t1.0\t\t1\n",
      "6.6\t\t2.9\t\t4.6\t\t1.3\t\t1\n",
      "5.2\t\t2.7\t\t3.9\t\t1.4\t\t1\n",
      "5.0\t\t2.0\t\t3.5\t\t1.0\t\t1\n",
      "5.9\t\t3.0\t\t4.2\t\t1.5\t\t1\n",
      "6.0\t\t2.2\t\t4.0\t\t1.0\t\t1\n",
      "6.1\t\t2.9\t\t4.7\t\t1.4\t\t1\n",
      "5.6\t\t2.9\t\t3.6\t\t1.3\t\t1\n",
      "6.7\t\t3.1\t\t4.4\t\t1.4\t\t1\n",
      "5.6\t\t3.0\t\t4.5\t\t1.5\t\t1\n",
      "5.8\t\t2.7\t\t4.1\t\t1.0\t\t1\n",
      "6.2\t\t2.2\t\t4.5\t\t1.5\t\t1\n",
      "5.6\t\t2.5\t\t3.9\t\t1.1\t\t1\n",
      "5.9\t\t3.2\t\t4.8\t\t1.8\t\t1\n",
      "6.1\t\t2.8\t\t4.0\t\t1.3\t\t1\n",
      "6.3\t\t2.5\t\t4.9\t\t1.5\t\t1\n",
      "6.1\t\t2.8\t\t4.7\t\t1.2\t\t1\n",
      "6.4\t\t2.9\t\t4.3\t\t1.3\t\t1\n",
      "6.6\t\t3.0\t\t4.4\t\t1.4\t\t1\n",
      "6.8\t\t2.8\t\t4.8\t\t1.4\t\t1\n",
      "6.7\t\t3.0\t\t5.0\t\t1.7\t\t1\n",
      "6.0\t\t2.9\t\t4.5\t\t1.5\t\t1\n",
      "5.7\t\t2.6\t\t3.5\t\t1.0\t\t1\n",
      "5.5\t\t2.4\t\t3.8\t\t1.1\t\t1\n",
      "5.5\t\t2.4\t\t3.7\t\t1.0\t\t1\n",
      "5.8\t\t2.7\t\t3.9\t\t1.2\t\t1\n",
      "6.0\t\t2.7\t\t5.1\t\t1.6\t\t1\n",
      "5.4\t\t3.0\t\t4.5\t\t1.5\t\t1\n",
      "6.0\t\t3.4\t\t4.5\t\t1.6\t\t1\n",
      "6.7\t\t3.1\t\t4.7\t\t1.5\t\t1\n",
      "6.3\t\t2.3\t\t4.4\t\t1.3\t\t1\n",
      "5.6\t\t3.0\t\t4.1\t\t1.3\t\t1\n",
      "5.5\t\t2.5\t\t4.0\t\t1.3\t\t1\n",
      "5.5\t\t2.6\t\t4.4\t\t1.2\t\t1\n",
      "6.1\t\t3.0\t\t4.6\t\t1.4\t\t1\n",
      "5.8\t\t2.6\t\t4.0\t\t1.2\t\t1\n",
      "5.0\t\t2.3\t\t3.3\t\t1.0\t\t1\n",
      "5.6\t\t2.7\t\t4.2\t\t1.3\t\t1\n",
      "5.7\t\t3.0\t\t4.2\t\t1.2\t\t1\n",
      "5.7\t\t2.9\t\t4.2\t\t1.3\t\t1\n",
      "6.2\t\t2.9\t\t4.3\t\t1.3\t\t1\n",
      "5.1\t\t2.5\t\t3.0\t\t1.1\t\t1\n",
      "5.7\t\t2.8\t\t4.1\t\t1.3\t\t1\n",
      "6.3\t\t3.3\t\t6.0\t\t2.5\t\t2\n",
      "5.8\t\t2.7\t\t5.1\t\t1.9\t\t2\n",
      "7.1\t\t3.0\t\t5.9\t\t2.1\t\t2\n",
      "6.3\t\t2.9\t\t5.6\t\t1.8\t\t2\n",
      "6.5\t\t3.0\t\t5.8\t\t2.2\t\t2\n",
      "7.6\t\t3.0\t\t6.6\t\t2.1\t\t2\n",
      "4.9\t\t2.5\t\t4.5\t\t1.7\t\t2\n",
      "7.3\t\t2.9\t\t6.3\t\t1.8\t\t2\n",
      "6.7\t\t2.5\t\t5.8\t\t1.8\t\t2\n",
      "7.2\t\t3.6\t\t6.1\t\t2.5\t\t2\n",
      "6.5\t\t3.2\t\t5.1\t\t2.0\t\t2\n",
      "6.4\t\t2.7\t\t5.3\t\t1.9\t\t2\n",
      "6.8\t\t3.0\t\t5.5\t\t2.1\t\t2\n",
      "5.7\t\t2.5\t\t5.0\t\t2.0\t\t2\n",
      "5.8\t\t2.8\t\t5.1\t\t2.4\t\t2\n",
      "6.4\t\t3.2\t\t5.3\t\t2.3\t\t2\n",
      "6.5\t\t3.0\t\t5.5\t\t1.8\t\t2\n",
      "7.7\t\t3.8\t\t6.7\t\t2.2\t\t2\n",
      "7.7\t\t2.6\t\t6.9\t\t2.3\t\t2\n",
      "6.0\t\t2.2\t\t5.0\t\t1.5\t\t2\n",
      "6.9\t\t3.2\t\t5.7\t\t2.3\t\t2\n",
      "5.6\t\t2.8\t\t4.9\t\t2.0\t\t2\n",
      "7.7\t\t2.8\t\t6.7\t\t2.0\t\t2\n",
      "6.3\t\t2.7\t\t4.9\t\t1.8\t\t2\n",
      "6.7\t\t3.3\t\t5.7\t\t2.1\t\t2\n",
      "7.2\t\t3.2\t\t6.0\t\t1.8\t\t2\n",
      "6.2\t\t2.8\t\t4.8\t\t1.8\t\t2\n",
      "6.1\t\t3.0\t\t4.9\t\t1.8\t\t2\n",
      "6.4\t\t2.8\t\t5.6\t\t2.1\t\t2\n",
      "7.2\t\t3.0\t\t5.8\t\t1.6\t\t2\n",
      "7.4\t\t2.8\t\t6.1\t\t1.9\t\t2\n",
      "7.9\t\t3.8\t\t6.4\t\t2.0\t\t2\n",
      "6.4\t\t2.8\t\t5.6\t\t2.2\t\t2\n",
      "6.3\t\t2.8\t\t5.1\t\t1.5\t\t2\n",
      "6.1\t\t2.6\t\t5.6\t\t1.4\t\t2\n",
      "7.7\t\t3.0\t\t6.1\t\t2.3\t\t2\n",
      "6.3\t\t3.4\t\t5.6\t\t2.4\t\t2\n",
      "6.4\t\t3.1\t\t5.5\t\t1.8\t\t2\n",
      "6.0\t\t3.0\t\t4.8\t\t1.8\t\t2\n",
      "6.9\t\t3.1\t\t5.4\t\t2.1\t\t2\n",
      "6.7\t\t3.1\t\t5.6\t\t2.4\t\t2\n",
      "6.9\t\t3.1\t\t5.1\t\t2.3\t\t2\n",
      "5.8\t\t2.7\t\t5.1\t\t1.9\t\t2\n",
      "6.8\t\t3.2\t\t5.9\t\t2.3\t\t2\n",
      "6.7\t\t3.3\t\t5.7\t\t2.5\t\t2\n",
      "6.7\t\t3.0\t\t5.2\t\t2.3\t\t2\n",
      "6.3\t\t2.5\t\t5.0\t\t1.9\t\t2\n",
      "6.5\t\t3.0\t\t5.2\t\t2.0\t\t2\n",
      "6.2\t\t3.4\t\t5.4\t\t2.3\t\t2\n",
      "5.9\t\t3.0\t\t5.1\t\t1.8\t\t2\n"
     ]
    }
   ],
   "source": [
    "# Define feature names\n",
    "feature_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "# Display the header\n",
    "header = \"   \".join(feature_names + ['species'])\n",
    "print(header)\n",
    "\n",
    "# Display each row of the dataset\n",
    "for i in range(len(X)):\n",
    "    row_data = \"\\t\\t\".join([str(x) for x in X[i]] + [str(y[i])])\n",
    "    print(row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez que le code suivant affiche bien des *True*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(X.shape == (150,4))\n",
    "print(y.shape == (150,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparez l'ensemble d'apprentissage en deux en utilisant la fonction train_test_split de sckit-learn. Un ensemble d'apprentissage *train* et un ensemble de *test*. Vous prendrez 1/3 des images pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test, y_train, y_test = train_test_split(X, y, test_size=(1/3), random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez les dimensions des données produites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 -> (100, 4) (100,)\n",
      "50.0 -> (50, 4) (50,)\n"
     ]
    }
   ],
   "source": [
    "print(2*len(X)/3,'->',train.shape,y_train.shape)\n",
    "print(len(X)/3,'->',test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un classifieur *iris_classifier* correspondant à un réseau entièrement connecté de 3 couches cachées de tailles [10,20,10]. Après chaque couche cachée, vous appliquerez une fonction d'activation de type ReLU. N'oubliez pas la dernière couche de sortie. Vous utiliseriez `torch.nn.Sequential` pour faire cette question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "##https://towardsdatascience.com/how-to-code-a-simple-neural-network-in-pytorch-for-absolute-beginners-8f5209c50fdd\n",
    "\n",
    "## turn the data into tensors\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un objet `iter_train` permettant de parcourir la base de donnée d'entrainement avec des batchs aléatoires de taille 32. Vous utiliserez les classes `TensorDataset` et `DataLoader` pour cette question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un objet `iter_test` permettant de parcourir la base de donnée de test avec des batchs de taille 10 concervant l'ordre d'origine des exemples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez une optimiser de type gradient stochastique initialisé avec un taux d'apprentissage de $10^{-2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissze un critère de type cross-entropie qui sera utilisé comme fonction de coût optimisant notre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuez 100 époques d'apprentissage du classifieur `iris_classifier` avec les données de `iter_train`. Vous utiliserez pour celà un algorithme de gradient stochastique avec une fonction de coût de type cross-entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /100, loss= 0.8554646968841553\n",
      "10 /100, loss= 1.0755116939544678\n",
      "20 /100, loss= 1.0671064853668213\n",
      "30 /100, loss= 0.9227153658866882\n",
      "40 /100, loss= 0.9295974969863892\n",
      "50 /100, loss= 0.5762283802032471\n",
      "60 /100, loss= 0.479737788438797\n",
      "70 /100, loss= 0.6177878379821777\n",
      "80 /100, loss= 0.33995407819747925\n",
      "90 /100, loss= 0.4962453544139862\n",
      "99 /100, loss= 0.3136560320854187\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluez les performances du réseau appris à la  question précédente sur les données de test de `iter_test`. Pour faire  cette  question vous calculerez dans une boucle le nombre de fois que l'algorithme s'est trompé sur la base de test. Pensez à désactiver le calcul des gradients sur la base de test afin de pas perturbé avec des données de tests de nouveaux apprentissages de votre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test: 78.0%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relancez les lignes effectuant l'apprentissage et l'évaluation. Comment évolue les performances d'apprentissage ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez tensorboard pour visualiser le graphe correspondant à votre réseau et les différentes courbes correspondant à l'apprentissage de ce dernier.\n",
    "\n",
    "Vous pouvez pour cela:\n",
    "- Soit installez le plugin tensorboard pour jupyter: pip3 install --user jupyter-tensorboard\n",
    "\n",
    "Puis vous suivez les informations d'écrit sur la page: https://github.com/lspvic/jupyter_tensorboard\n",
    "- Soit lancer dans un terminal: tensorboard --logdir=.\n",
    "\n",
    "Puis vous vous connectez à http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch: Définition d'un réseau couche par couche\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans cette partie redéfinir le réseau couche par couche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez une classe `Net` définissant le réseau précédant sans utiliser de `torch.nn.Sequential`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprenez ce réseau sur les données d'apprentissage de la base IRIS avec un algorithme de descende de gradient de type AdaGrad dont le taux d'apprentissage est de $10^{-2}$ avec une fonction de coût de type cross-entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /200, loss= 1.1917170286178589\n",
      "100 /200, loss= 0.3672744035720825\n",
      "200/200, loss= 0.13490986824035645\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez le réseau que vous venez d'apprendre sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test: 96.0%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardez le modèle que vous venez d'apprendre dans un fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez le réseau que vous venez de sauvegarder et vérifier que les performances sur la base de test n'ont pas changé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test: 96.0%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparez les graphes des deux méthodes dans tensorboard. Retrouvez-vous les même éléments ? Qu'est ce qui diffère entre les deux versions ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison avec un SVM \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la librairie sckit-learn et le cours de Machine learning du premier semestre, trouver les performances du meilleur SVM sur ces données et comparer les performances avec celle du réseau de neurone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        16\n",
      "           1     1.0000    0.9474    0.9730        19\n",
      "           2     0.9375    1.0000    0.9677        15\n",
      "\n",
      "   micro avg     0.9800    0.9800    0.9800        50\n",
      "   macro avg     0.9792    0.9825    0.9802        50\n",
      "weighted avg     0.9812    0.9800    0.9801        50\n",
      "\n",
      "[[16  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0 15]] 0.8 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lechervy/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import *\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
