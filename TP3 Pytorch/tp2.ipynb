{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP2: Premier réseau de neurone avec PyTorch\n",
    "=============\n",
    "\n",
    "Introduction au sujet\n",
    "-----\n",
    "\n",
    "L'objectif de ce sujet est de mettre en place un premier réseau de neurone pour classer des fleurs de la base IRIS.\n",
    "\n",
    "Le code est à écrire en python3 à la suite des questions dans ce fichier. Vous appuierez soit sur le bouton *run cell*, soit sur les touches *Ctrl-Entrée*, à l’intérieur de la zone de saisie, pour lancer l'exécution de vos commandes. Si la commande est en cours d’exécution une étoile apparaît à côté de la zone de saisie de la commande : In [\\*]. Une fois le calcul achevé, l'étoile est remplacée par le numéro du run permettant de retrouver par la suite dans quel ordre ont été lancés chaque bloc.\n",
    "\n",
    "N'hésitez pas à regarder régulièrement la documentation de ces librairies, des exemples d'utilisation accompagnent généralement l'explication de chaque fonction.\n",
    "\n",
    "Langage utilisé:\n",
    "- Python 3: https://docs.python.org/3/\n",
    "\n",
    "Librairie de math:\n",
    "- Numpy: https://docs.scipy.org/doc/numpy/reference/\n",
    "- Scipy: https://docs.scipy.org/doc/scipy/reference/\n",
    "\n",
    "Librairie d'affichage de données:\n",
    "- Matplotilb: https://matplotlib.org/contents.html\n",
    "\n",
    "Librairie Pytorch:\n",
    "- PyTorch: https: https://pytorch.org/docs/stable/\n",
    "\n",
    "Commencez par importer les librairies nécessaires au TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 01:39:27.797395: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-05 01:39:28.515739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 01:39:30.289223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Import numpy et matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import de scikit-learn\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch: Premier réseau sur la base IRIS\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans ce TP étudier la base *IRIS* et tester un réseau entièrement connecté dessus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencez par charger la base *IRIS* avec sckit-learn. Vous mettrez les descripteurs des fleurs dans une variable `X` et les labels dans une variable `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X,y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length   sepal_width   petal_length   petal_width   species\n",
      "5.1\t\t3.5\t\t1.4\t\t0.2\t\t0\n",
      "4.9\t\t3.0\t\t1.4\t\t0.2\t\t0\n",
      "4.7\t\t3.2\t\t1.3\t\t0.2\t\t0\n",
      "4.6\t\t3.1\t\t1.5\t\t0.2\t\t0\n",
      "5.0\t\t3.6\t\t1.4\t\t0.2\t\t0\n",
      "5.4\t\t3.9\t\t1.7\t\t0.4\t\t0\n",
      "4.6\t\t3.4\t\t1.4\t\t0.3\t\t0\n",
      "5.0\t\t3.4\t\t1.5\t\t0.2\t\t0\n",
      "4.4\t\t2.9\t\t1.4\t\t0.2\t\t0\n",
      "4.9\t\t3.1\t\t1.5\t\t0.1\t\t0\n",
      "5.4\t\t3.7\t\t1.5\t\t0.2\t\t0\n",
      "4.8\t\t3.4\t\t1.6\t\t0.2\t\t0\n",
      "4.8\t\t3.0\t\t1.4\t\t0.1\t\t0\n",
      "4.3\t\t3.0\t\t1.1\t\t0.1\t\t0\n",
      "5.8\t\t4.0\t\t1.2\t\t0.2\t\t0\n",
      "5.7\t\t4.4\t\t1.5\t\t0.4\t\t0\n",
      "5.4\t\t3.9\t\t1.3\t\t0.4\t\t0\n",
      "5.1\t\t3.5\t\t1.4\t\t0.3\t\t0\n",
      "5.7\t\t3.8\t\t1.7\t\t0.3\t\t0\n",
      "5.1\t\t3.8\t\t1.5\t\t0.3\t\t0\n",
      "5.4\t\t3.4\t\t1.7\t\t0.2\t\t0\n",
      "5.1\t\t3.7\t\t1.5\t\t0.4\t\t0\n",
      "4.6\t\t3.6\t\t1.0\t\t0.2\t\t0\n",
      "5.1\t\t3.3\t\t1.7\t\t0.5\t\t0\n",
      "4.8\t\t3.4\t\t1.9\t\t0.2\t\t0\n",
      "5.0\t\t3.0\t\t1.6\t\t0.2\t\t0\n",
      "5.0\t\t3.4\t\t1.6\t\t0.4\t\t0\n",
      "5.2\t\t3.5\t\t1.5\t\t0.2\t\t0\n",
      "5.2\t\t3.4\t\t1.4\t\t0.2\t\t0\n",
      "4.7\t\t3.2\t\t1.6\t\t0.2\t\t0\n",
      "4.8\t\t3.1\t\t1.6\t\t0.2\t\t0\n",
      "5.4\t\t3.4\t\t1.5\t\t0.4\t\t0\n",
      "5.2\t\t4.1\t\t1.5\t\t0.1\t\t0\n",
      "5.5\t\t4.2\t\t1.4\t\t0.2\t\t0\n",
      "4.9\t\t3.1\t\t1.5\t\t0.2\t\t0\n",
      "5.0\t\t3.2\t\t1.2\t\t0.2\t\t0\n",
      "5.5\t\t3.5\t\t1.3\t\t0.2\t\t0\n",
      "4.9\t\t3.6\t\t1.4\t\t0.1\t\t0\n",
      "4.4\t\t3.0\t\t1.3\t\t0.2\t\t0\n",
      "5.1\t\t3.4\t\t1.5\t\t0.2\t\t0\n",
      "5.0\t\t3.5\t\t1.3\t\t0.3\t\t0\n",
      "4.5\t\t2.3\t\t1.3\t\t0.3\t\t0\n",
      "4.4\t\t3.2\t\t1.3\t\t0.2\t\t0\n",
      "5.0\t\t3.5\t\t1.6\t\t0.6\t\t0\n",
      "5.1\t\t3.8\t\t1.9\t\t0.4\t\t0\n",
      "4.8\t\t3.0\t\t1.4\t\t0.3\t\t0\n",
      "5.1\t\t3.8\t\t1.6\t\t0.2\t\t0\n",
      "4.6\t\t3.2\t\t1.4\t\t0.2\t\t0\n",
      "5.3\t\t3.7\t\t1.5\t\t0.2\t\t0\n",
      "5.0\t\t3.3\t\t1.4\t\t0.2\t\t0\n",
      "7.0\t\t3.2\t\t4.7\t\t1.4\t\t1\n",
      "6.4\t\t3.2\t\t4.5\t\t1.5\t\t1\n",
      "6.9\t\t3.1\t\t4.9\t\t1.5\t\t1\n",
      "5.5\t\t2.3\t\t4.0\t\t1.3\t\t1\n",
      "6.5\t\t2.8\t\t4.6\t\t1.5\t\t1\n",
      "5.7\t\t2.8\t\t4.5\t\t1.3\t\t1\n",
      "6.3\t\t3.3\t\t4.7\t\t1.6\t\t1\n",
      "4.9\t\t2.4\t\t3.3\t\t1.0\t\t1\n",
      "6.6\t\t2.9\t\t4.6\t\t1.3\t\t1\n",
      "5.2\t\t2.7\t\t3.9\t\t1.4\t\t1\n",
      "5.0\t\t2.0\t\t3.5\t\t1.0\t\t1\n",
      "5.9\t\t3.0\t\t4.2\t\t1.5\t\t1\n",
      "6.0\t\t2.2\t\t4.0\t\t1.0\t\t1\n",
      "6.1\t\t2.9\t\t4.7\t\t1.4\t\t1\n",
      "5.6\t\t2.9\t\t3.6\t\t1.3\t\t1\n",
      "6.7\t\t3.1\t\t4.4\t\t1.4\t\t1\n",
      "5.6\t\t3.0\t\t4.5\t\t1.5\t\t1\n",
      "5.8\t\t2.7\t\t4.1\t\t1.0\t\t1\n",
      "6.2\t\t2.2\t\t4.5\t\t1.5\t\t1\n",
      "5.6\t\t2.5\t\t3.9\t\t1.1\t\t1\n",
      "5.9\t\t3.2\t\t4.8\t\t1.8\t\t1\n",
      "6.1\t\t2.8\t\t4.0\t\t1.3\t\t1\n",
      "6.3\t\t2.5\t\t4.9\t\t1.5\t\t1\n",
      "6.1\t\t2.8\t\t4.7\t\t1.2\t\t1\n",
      "6.4\t\t2.9\t\t4.3\t\t1.3\t\t1\n",
      "6.6\t\t3.0\t\t4.4\t\t1.4\t\t1\n",
      "6.8\t\t2.8\t\t4.8\t\t1.4\t\t1\n",
      "6.7\t\t3.0\t\t5.0\t\t1.7\t\t1\n",
      "6.0\t\t2.9\t\t4.5\t\t1.5\t\t1\n",
      "5.7\t\t2.6\t\t3.5\t\t1.0\t\t1\n",
      "5.5\t\t2.4\t\t3.8\t\t1.1\t\t1\n",
      "5.5\t\t2.4\t\t3.7\t\t1.0\t\t1\n",
      "5.8\t\t2.7\t\t3.9\t\t1.2\t\t1\n",
      "6.0\t\t2.7\t\t5.1\t\t1.6\t\t1\n",
      "5.4\t\t3.0\t\t4.5\t\t1.5\t\t1\n",
      "6.0\t\t3.4\t\t4.5\t\t1.6\t\t1\n",
      "6.7\t\t3.1\t\t4.7\t\t1.5\t\t1\n",
      "6.3\t\t2.3\t\t4.4\t\t1.3\t\t1\n",
      "5.6\t\t3.0\t\t4.1\t\t1.3\t\t1\n",
      "5.5\t\t2.5\t\t4.0\t\t1.3\t\t1\n",
      "5.5\t\t2.6\t\t4.4\t\t1.2\t\t1\n",
      "6.1\t\t3.0\t\t4.6\t\t1.4\t\t1\n",
      "5.8\t\t2.6\t\t4.0\t\t1.2\t\t1\n",
      "5.0\t\t2.3\t\t3.3\t\t1.0\t\t1\n",
      "5.6\t\t2.7\t\t4.2\t\t1.3\t\t1\n",
      "5.7\t\t3.0\t\t4.2\t\t1.2\t\t1\n",
      "5.7\t\t2.9\t\t4.2\t\t1.3\t\t1\n",
      "6.2\t\t2.9\t\t4.3\t\t1.3\t\t1\n",
      "5.1\t\t2.5\t\t3.0\t\t1.1\t\t1\n",
      "5.7\t\t2.8\t\t4.1\t\t1.3\t\t1\n",
      "6.3\t\t3.3\t\t6.0\t\t2.5\t\t2\n",
      "5.8\t\t2.7\t\t5.1\t\t1.9\t\t2\n",
      "7.1\t\t3.0\t\t5.9\t\t2.1\t\t2\n",
      "6.3\t\t2.9\t\t5.6\t\t1.8\t\t2\n",
      "6.5\t\t3.0\t\t5.8\t\t2.2\t\t2\n",
      "7.6\t\t3.0\t\t6.6\t\t2.1\t\t2\n",
      "4.9\t\t2.5\t\t4.5\t\t1.7\t\t2\n",
      "7.3\t\t2.9\t\t6.3\t\t1.8\t\t2\n",
      "6.7\t\t2.5\t\t5.8\t\t1.8\t\t2\n",
      "7.2\t\t3.6\t\t6.1\t\t2.5\t\t2\n",
      "6.5\t\t3.2\t\t5.1\t\t2.0\t\t2\n",
      "6.4\t\t2.7\t\t5.3\t\t1.9\t\t2\n",
      "6.8\t\t3.0\t\t5.5\t\t2.1\t\t2\n",
      "5.7\t\t2.5\t\t5.0\t\t2.0\t\t2\n",
      "5.8\t\t2.8\t\t5.1\t\t2.4\t\t2\n",
      "6.4\t\t3.2\t\t5.3\t\t2.3\t\t2\n",
      "6.5\t\t3.0\t\t5.5\t\t1.8\t\t2\n",
      "7.7\t\t3.8\t\t6.7\t\t2.2\t\t2\n",
      "7.7\t\t2.6\t\t6.9\t\t2.3\t\t2\n",
      "6.0\t\t2.2\t\t5.0\t\t1.5\t\t2\n",
      "6.9\t\t3.2\t\t5.7\t\t2.3\t\t2\n",
      "5.6\t\t2.8\t\t4.9\t\t2.0\t\t2\n",
      "7.7\t\t2.8\t\t6.7\t\t2.0\t\t2\n",
      "6.3\t\t2.7\t\t4.9\t\t1.8\t\t2\n",
      "6.7\t\t3.3\t\t5.7\t\t2.1\t\t2\n",
      "7.2\t\t3.2\t\t6.0\t\t1.8\t\t2\n",
      "6.2\t\t2.8\t\t4.8\t\t1.8\t\t2\n",
      "6.1\t\t3.0\t\t4.9\t\t1.8\t\t2\n",
      "6.4\t\t2.8\t\t5.6\t\t2.1\t\t2\n",
      "7.2\t\t3.0\t\t5.8\t\t1.6\t\t2\n",
      "7.4\t\t2.8\t\t6.1\t\t1.9\t\t2\n",
      "7.9\t\t3.8\t\t6.4\t\t2.0\t\t2\n",
      "6.4\t\t2.8\t\t5.6\t\t2.2\t\t2\n",
      "6.3\t\t2.8\t\t5.1\t\t1.5\t\t2\n",
      "6.1\t\t2.6\t\t5.6\t\t1.4\t\t2\n",
      "7.7\t\t3.0\t\t6.1\t\t2.3\t\t2\n",
      "6.3\t\t3.4\t\t5.6\t\t2.4\t\t2\n",
      "6.4\t\t3.1\t\t5.5\t\t1.8\t\t2\n",
      "6.0\t\t3.0\t\t4.8\t\t1.8\t\t2\n",
      "6.9\t\t3.1\t\t5.4\t\t2.1\t\t2\n",
      "6.7\t\t3.1\t\t5.6\t\t2.4\t\t2\n",
      "6.9\t\t3.1\t\t5.1\t\t2.3\t\t2\n",
      "5.8\t\t2.7\t\t5.1\t\t1.9\t\t2\n",
      "6.8\t\t3.2\t\t5.9\t\t2.3\t\t2\n",
      "6.7\t\t3.3\t\t5.7\t\t2.5\t\t2\n",
      "6.7\t\t3.0\t\t5.2\t\t2.3\t\t2\n",
      "6.3\t\t2.5\t\t5.0\t\t1.9\t\t2\n",
      "6.5\t\t3.0\t\t5.2\t\t2.0\t\t2\n",
      "6.2\t\t3.4\t\t5.4\t\t2.3\t\t2\n",
      "5.9\t\t3.0\t\t5.1\t\t1.8\t\t2\n"
     ]
    }
   ],
   "source": [
    "# Define feature names\n",
    "feature_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "# Display the header\n",
    "header = \"   \".join(feature_names + ['species'])\n",
    "print(header)\n",
    "\n",
    "# Display each row of the dataset\n",
    "for i in range(len(X)):\n",
    "    row_data = \"\\t\\t\".join([str(x) for x in X[i]] + [str(y[i])])\n",
    "    print(row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez que le code suivant affiche bien des *True*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(X.shape == (150,4))\n",
    "print(y.shape == (150,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparez l'ensemble d'apprentissage en deux en utilisant la fonction train_test_split de sckit-learn. Un ensemble d'apprentissage *train* et un ensemble de *test*. Vous prendrez 1/3 des images pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test, y_train, y_test = train_test_split(X, y, test_size=(1/3), random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez les dimensions des données produites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 -> (100, 4) (100,)\n",
      "50.0 -> (50, 4) (50,)\n"
     ]
    }
   ],
   "source": [
    "print(2*len(X)/3,'->',train.shape,y_train.shape)\n",
    "print(len(X)/3,'->',test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un classifieur *iris_classifier* correspondant à un réseau entièrement connecté de 3 couches cachées de tailles [10,20,10]. Après chaque couche cachée, vous appliquerez une fonction d'activation de type ReLU. N'oubliez pas la dernière couche de sortie. Vous utiliseriez `torch.nn.Sequential` pour faire cette question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Définir le classifieur iris_classifier\n",
    "iris_classifier = nn.Sequential(\n",
    "    nn.Linear(4, 10),  # Couche d'entrée: 4 neurones, sortie: 10 neurones\n",
    "    nn.ReLU(),          # Fonction d'activation ReLU\n",
    "    nn.Linear(10, 20),  # Couche cachée: 10 neurones en entrée, 20 neurones en sortie\n",
    "    nn.ReLU(),          # Fonction d'activation ReLU\n",
    "    nn.Linear(20, 10),  # Couche cachée: 20 neurones en entrée, 10 neurones en sortie\n",
    "    nn.ReLU(),          # Fonction d'activation ReLU\n",
    "    nn.Linear(10, 3),   # Couche de sortie: 10 neurones en entrée, 3 neurones en sortie (classes)\n",
    "    nn.Softmax(dim=1)   # Fonction d'activation Softmax pour obtenir les probabilités des classes\n",
    ")\n",
    "\n",
    "# Afficher l'architecture du classifieur\n",
    "print(iris_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un objet `iter_train` permettant de parcourir la base de donnée d'entrainement avec des batchs aléatoires de taille 32. Vous utiliserez les classes `TensorDataset` et `DataLoader` pour cette question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de mini-lots dans l'itérateur d'entraînement: 4\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Créer un TensorDataset à partir des données d'entraînement et des étiquettes\n",
    "train_dataset = TensorDataset(torch.tensor(train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "\n",
    "# Définir DataLoader pour itérer sur les mini-lots aléatoires de taille 32\n",
    "iter_train = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Vérifier le nombre total de mini-lots dans l'itérateur\n",
    "num_batches = len(iter_train)\n",
    "\n",
    "print(\"Nombre total de mini-lots dans l'itérateur d'entraînement:\", num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un objet `iter_test` permettant de parcourir la base de donnée de test avec des batchs de taille 10 concervant l'ordre d'origine des exemples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de mini-lots dans l'itérateur de test: 5\n"
     ]
    }
   ],
   "source": [
    "# Créer un TensorDataset à partir des données de test et des étiquettes\n",
    "test_dataset = TensorDataset(torch.tensor(test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "# Définir DataLoader pour itérer sur les mini-lots de taille 10 tout en conservant l'ordre\n",
    "iter_test = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# Vérifier le nombre total de mini-lots dans l'itérateur\n",
    "num_batches_test = len(iter_test)\n",
    "print(\"Nombre total de mini-lots dans l'itérateur de test:\", num_batches_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez une optimiser de type gradient stochastique initialisé avec un taux d'apprentissage de $10^{-2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux d'apprentissage de l'optimiseur SGD: 0.01\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Définir l'optimiseur SGD avec un taux d'apprentissage de 10^-2\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(iris_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Vérifier le taux d'apprentissage de l'optimiseur\n",
    "print(\"Taux d'apprentissage de l'optimiseur SGD:\", optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissze un critère de type cross-entropie qui sera utilisé comme fonction de coût optimisant notre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critère de perte CrossEntropy: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Définir le critère de perte CrossEntropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Afficher le critère de perte\n",
    "print(\"Critère de perte CrossEntropy:\", criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuez 100 époques d'apprentissage du classifieur `iris_classifier` avec les données de `iter_train`. Vous utiliserez pour celà un algorithme de gradient stochastique avec une fonction de coût de type cross-entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9998/2822133625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Calculer la perte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Effectuer une rétropropagation (backward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Définir l'optimiseur SGD avec un taux d'apprentissage de 10^-2\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(iris_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Définir le critère de perte CrossEntropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Nombre d'époques\n",
    "num_epochs = 100\n",
    "\n",
    "# Boucle d'apprentissage sur les époques\n",
    "for epoch in range(num_epochs):\n",
    "    # Boucle sur les mini-lots dans iter_train\n",
    "    for inputs, labels in iter_train:\n",
    "        # Remettre à zéro les gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Effectuer une propagation avant (forward)\n",
    "        outputs = iris_classifier(inputs)\n",
    "        \n",
    "        # Calculer la perte\n",
    "        loss = criterion(outputs, torch.argmax(labels, axis=1))\n",
    "        \n",
    "        # Effectuer une rétropropagation (backward)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Mettre à jour les poids\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Afficher la perte moyenne pour chaque époque\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Entraînement terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /100, loss= 0.8554646968841553\n",
      "10 /100, loss= 1.0755116939544678\n",
      "20 /100, loss= 1.0671064853668213\n",
      "30 /100, loss= 0.9227153658866882\n",
      "40 /100, loss= 0.9295974969863892\n",
      "50 /100, loss= 0.5762283802032471\n",
      "60 /100, loss= 0.479737788438797\n",
      "70 /100, loss= 0.6177878379821777\n",
      "80 /100, loss= 0.33995407819747925\n",
      "90 /100, loss= 0.4962453544139862\n",
      "99 /100, loss= 0.3136560320854187\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluez les performances du réseau appris à la  question précédente sur les données de test de `iter_test`. Pour faire  cette  question vous calculerez dans une boucle le nombre de fois que l'algorithme s'est trompé sur la base de test. Pensez à désactiver le calcul des gradients sur la base de test afin de pas perturbé avec des données de tests de nouveaux apprentissages de votre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test: 78.0%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relancez les lignes effectuant l'apprentissage et l'évaluation. Comment évolue les performances d'apprentissage ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez tensorboard pour visualiser le graphe correspondant à votre réseau et les différentes courbes correspondant à l'apprentissage de ce dernier.\n",
    "\n",
    "Vous pouvez pour cela:\n",
    "- Soit installez le plugin tensorboard pour jupyter: pip3 install --user jupyter-tensorboard\n",
    "\n",
    "Puis vous suivez les informations d'écrit sur la page: https://github.com/lspvic/jupyter_tensorboard\n",
    "- Soit lancer dans un terminal: tensorboard --logdir=.\n",
    "\n",
    "Puis vous vous connectez à http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch: Définition d'un réseau couche par couche\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans cette partie redéfinir le réseau couche par couche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez une classe `Net` définissant le réseau précédant sans utiliser de `torch.nn.Sequential`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (fc4): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 10)  # Input size: 4, Output size: 10\n",
    "        self.fc2 = nn.Linear(10, 20)  # Input size: 10, Output size: 20\n",
    "        self.fc3 = nn.Linear(20, 10)   # Input size: 20, Output size: 10\n",
    "        self.fc4 = nn.Linear(10, 3)    # Input size: 10, Output size: 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "iris_classifier = Net()\n",
    "\n",
    "# Print the model architecture\n",
    "print(iris_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprenez ce réseau sur les données d'apprentissage de la base IRIS avec un algorithme de descende de gradient de type AdaGrad dont le taux d'apprentissage est de $10^{-2}$ avec une fonction de coût de type cross-entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /200, loss= 1.1917170286178589\n",
      "100 /200, loss= 0.3672744035720825\n",
      "200/200, loss= 0.13490986824035645\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez le réseau que vous venez d'apprendre sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test: 96.0%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardez le modèle que vous venez d'apprendre dans un fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez le réseau que vous venez de sauvegarder et vérifier que les performances sur la base de test n'ont pas changé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test: 96.0%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparez les graphes des deux méthodes dans tensorboard. Retrouvez-vous les même éléments ? Qu'est ce qui diffère entre les deux versions ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison avec un SVM \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la librairie sckit-learn et le cours de Machine learning du premier semestre, trouver les performances du meilleur SVM sur ces données et comparer les performances avec celle du réseau de neurone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        16\n",
      "           1     1.0000    0.9474    0.9730        19\n",
      "           2     0.9375    1.0000    0.9677        15\n",
      "\n",
      "   micro avg     0.9800    0.9800    0.9800        50\n",
      "   macro avg     0.9792    0.9825    0.9802        50\n",
      "weighted avg     0.9812    0.9800    0.9801        50\n",
      "\n",
      "[[16  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0 15]] 0.8 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lechervy/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import *\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
